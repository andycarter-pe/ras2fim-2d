{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7a6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c4550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Constants from config file ----\n",
    "\n",
    "# model hydrofabric geopackage\n",
    "str_model_hydrofabric_gpkg = r'E:\\sample_2d_output\\BLE_LBSG_501_p02\\model_hydrofabric.gpkg'\n",
    "\n",
    "# average time lookback to determine cells wsel 'stability' in hours\n",
    "int_time_rolling_avg = 4\n",
    "\n",
    "# additional time to extend run (in hours)\n",
    "int_buffer_time = 5\n",
    "\n",
    "# --- HEC RAS model to spawn ---\n",
    "# directory containing the HEC-RAS files to spawn new runs/geometry\n",
    "str_ras_path = r'E:\\HECRAS_2D_12070205\\base_model_20240414_copy'\n",
    "\n",
    "str_boundary_to_edit = \"Emitter1\"\n",
    "\n",
    "int_geom_to_copy = 1\n",
    "int_u_to_copy = 1\n",
    "int_p_to_copy = 1\n",
    "# ---  ---\n",
    "\n",
    "str_simulation_start_date = \"01Jan2000\"\n",
    "\n",
    "# TODO - this will change for every run\n",
    "flt_lower_flow = 500 # low flow in cfs\n",
    "flt_upper_flow = 15000 #high flow in cfs - set to None if only single flow needed\n",
    "flt_delta_q = 1500 #flow to step in cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5812eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "def fn_format_flow_as_string(flt_flow):\n",
    "    # format a flow value to no more than 5 characters\n",
    "    # if bigger than 100000 ... returns 1.0e5\n",
    "    \n",
    "    # works up to 990 million cfs\n",
    "    if flt_flow >= 100000:\n",
    "        formatted_flow = \"{:.1e}\".format(flt_flow)\n",
    "        parts = formatted_flow.split('e')\n",
    "        formatted_flow = \"{}e{}\".format(parts[0], int(parts[1]))  # Reconstructing the notation\n",
    "        if len(formatted_flow) > 8:  # Ensuring the total length is 8 characters\n",
    "            formatted_flow = \"{:.1e}\".format(flt_flow).replace(\"e\", \"e+\")\n",
    "    else:\n",
    "        formatted_flow = str(flt_flow)\n",
    "    \n",
    "    # returns a string\n",
    "    return(formatted_flow)\n",
    "# ---------------\n",
    "\n",
    "# --------------------\n",
    "def fn_list_filename_from_ras_prj(str_ras_prj_path, str_line_header):\n",
    "    # Open the file\n",
    "    with open(list_proj_title_files[0], 'r') as file:\n",
    "        # Read lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Initialize a list to store File values\n",
    "        list_names = []\n",
    "\n",
    "        # Iterate through each line\n",
    "        for line in lines:\n",
    "            # Check if the line contains \"Unsteady File\"\n",
    "            if str_line_header in line:\n",
    "                # Extract the value after \"Unsteady File=\"\n",
    "                value = line.split(str_line_header)[1].strip()\n",
    "                # Add the value to the list\n",
    "                list_names.append(value)\n",
    "        return(list_names)\n",
    "# --------------------\n",
    "\n",
    "# ----------\n",
    "def fn_extract_numbers_from_strings(lst):\n",
    "    numbers = []\n",
    "    for item in lst:\n",
    "        number = re.search(r'\\d+', item).group()\n",
    "        numbers.append(int(number))\n",
    "    return numbers\n",
    "# ----------\n",
    "\n",
    "# --------------\n",
    "def fn_list_of_file_exists(list_filepaths):\n",
    "    \n",
    "    list_b_return = []\n",
    "    for filepath in list_filepaths:\n",
    "        if os.path.exists(filepath):\n",
    "            list_b_return.append(True)\n",
    "        else:\n",
    "            list_b_return.append(False)\n",
    "    return(list_b_return)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc35ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_build_plan_names(flt_lower_flow, flt_upper_flow, dict_mainstem):\n",
    "    str_run_name, str_short_plan = None, None\n",
    "    \n",
    "    # systematic naming of plans (if only one flow, flt_upper_flow should be None)\n",
    "    is_single_flow = False\n",
    "    \n",
    "    try:\n",
    "        if flt_upper_flow == None:\n",
    "            is_single_flow = True\n",
    "            \n",
    "        str_mainstem = str(int(dict_mainstem['mainstem']))\n",
    "        str_start_node = dict_mainstem['id_start_node']\n",
    "        int_firehose_time = int(dict_mainstem['time_sim_hr'])\n",
    "        str_flow =  str(int(flt_lower_flow))\n",
    "\n",
    "        str_run_name = str_mainstem + \"_\" + str_start_node + \"_\" + str(int_firehose_time) + \"-\" + \"hr\"\n",
    "        str_run_name += \"_\" + str(int(flt_lower_flow)) + \"-cfs\"\n",
    "\n",
    "        if not is_single_flow:  \n",
    "            # add the upper range flow to the description\n",
    "            str_run_name += \"_to_\" + str(int(flt_upper_flow)) + \"-cfs\"\n",
    "\n",
    "        str_short_plan = str_start_node + '-' + fn_format_flow_as_string(flt_lower_flow)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return(str_run_name, str_short_plan)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d3ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "def fn_list_of_ras_projects(str_ras_path):\n",
    "\n",
    "    list_proj_title_files = []\n",
    "\n",
    "    # locate the valid HEC-RAS project\n",
    "    try:\n",
    "        list_prj_files = [os.path.join(str_ras_path, f) for f in os.listdir(str_ras_path) if f.endswith('.prj')]\n",
    "\n",
    "        if len(list_prj_files) > 0:\n",
    "            list_proj_title_files = []\n",
    "\n",
    "            for file_path in list_prj_files:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    contents = file.read()\n",
    "                    if 'Proj Title' in contents:\n",
    "                        list_proj_title_files.append(file_path)\n",
    "\n",
    "            for file_path in list_proj_title_files:\n",
    "                print(f\"Valid HEC-RAS Project: {file_path}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"No HEC-RAS PRJ found in {str_ras_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    return(list_proj_title_files)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b0eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ....................\n",
    "def fn_copy_geom_file(list_proj_title_files, int_geom_to_copy, dict_flows):\n",
    "    \n",
    "    str_copy_to_geom_full_path = None\n",
    "    str_copy_to_geom_hdf_full_path = None\n",
    "\n",
    "    # Splitting the path into folder and filename\n",
    "    str_prj_folder, str_filename = os.path.split(list_proj_title_files[0])\n",
    "\n",
    "    # Splitting the filename and its extension\n",
    "    str_file_only, str_extension = os.path.splitext(str_filename)\n",
    "\n",
    "    # determine the geometry files that are in the project\n",
    "    list_geom_names = fn_list_filename_from_ras_prj(list_proj_title_files[0], \"Geom File=\")\n",
    "    list_geom_int = fn_extract_numbers_from_strings(list_geom_names)\n",
    "\n",
    "    list_geom_hdf_fullpath = []\n",
    "    list_geom_fullpath = []\n",
    "\n",
    "    for geom_item in list_geom_names:\n",
    "        str_hdf_geom_file = str_file_only + \".\" + geom_item + \".hdf\"\n",
    "        str_geom_file = str_file_only + \".\" + geom_item\n",
    "\n",
    "        # Combine the folder path and filename\n",
    "        str_hdf_full_path = os.path.join(str_prj_folder, str_hdf_geom_file)\n",
    "        str_geom_full_path = os.path.join(str_prj_folder, str_geom_file)\n",
    "\n",
    "        list_geom_hdf_fullpath.append(str_hdf_full_path)\n",
    "        list_geom_fullpath.append(str_geom_full_path)\n",
    "\n",
    "    list_b_hdf_exists = []\n",
    "\n",
    "    list_b_hdf_exists = fn_list_of_file_exists(list_geom_hdf_fullpath)\n",
    "    list_b_geom_exists = fn_list_of_file_exists(list_geom_fullpath)\n",
    "\n",
    "    # Assuming all lists have the same length\n",
    "    data = {\n",
    "        'geom_int': list_geom_int,\n",
    "        'geom_name': list_geom_names,\n",
    "        'hdf_path': list_geom_hdf_fullpath,\n",
    "        'hdf_exists': list_b_hdf_exists,\n",
    "        'geom_path': list_geom_fullpath,\n",
    "        'geom_exists': list_b_geom_exists\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df[(df['geom_int'] == int_geom_to_copy) & (df['hdf_exists']) & (df['geom_exists'])]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_filtered.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Geometry Match Found')\n",
    "\n",
    "        # Determine the highest number in geom_int\n",
    "        highest_geom_int = df['geom_int'].max()\n",
    "\n",
    "        # Add one to the highest number\n",
    "        next_geom_int = highest_geom_int + 1\n",
    "\n",
    "        # Convert next_geom_int to string with leading zero padding if necessary\n",
    "        next_geom_int_str = '{:02d}'.format(next_geom_int)\n",
    "\n",
    "        # copy geom file\n",
    "        str_copy_from = df_filtered.iloc[0]['geom_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str\n",
    "        str_copy_to_geom_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from, str_copy_to_geom_full_path)\n",
    "        print(f\"Copied {str_copy_from} to {str_copy_to_geom_full_path}\")\n",
    "\n",
    "        # copy the hdf geom file\n",
    "        str_copy_from_hdf = df_filtered.iloc[0]['hdf_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str + \".hdf\"\n",
    "        str_copy_to_geom_hdf_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from_hdf, str_copy_to_geom_hdf_full_path)\n",
    "        print(f\"Copied {str_copy_from_hdf} to {str_copy_to_geom_hdf_full_path}\")\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~\n",
    "        # add the geom to the project file\n",
    "\n",
    "        # Read the contents of the file\n",
    "        with open(list_proj_title_files[0], 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the last occurrence of a line starting with \"Geom File=\"\n",
    "        last_geom_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].strip().startswith(\"Geom File=\"):\n",
    "                last_geom_index = i\n",
    "\n",
    "        # Insert a new line after the last occurrence of \"Geom File=\"\n",
    "        if last_geom_index != -1:\n",
    "            lines.insert(last_geom_index + 1, \"Geom File=g\" + next_geom_int_str + \"\\n\")\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(list_proj_title_files[0], 'w') as file:\n",
    "            file.writelines(lines)\n",
    "            \n",
    "        # ---------------------\n",
    "        # Within the geom file, change the plan \n",
    "\n",
    "        # Read the file content\n",
    "        with open(str_copy_to_geom_full_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # --- Append the plan title in the plan file\n",
    "        # Find indices and lines that start with \"Flow File=\"\n",
    "        list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Geom Title=', line)]\n",
    "\n",
    "        # Replace lines in the list\n",
    "        for index, _ in list_tup_match:\n",
    "            lines[index] = \"Geom Title=\" + dict_flows['run_name'] + \"_geom\" + \"\\n\"\n",
    "            \n",
    "        # Write the modified lines back to the file\n",
    "        with open(str_copy_to_geom_full_path, \"w\") as file:\n",
    "            file.writelines(lines)\n",
    "\n",
    "    else:\n",
    "        # Otherwise, print an error statement\n",
    "        print(\"Error: Geometry HDF and gXX not available.\")\n",
    "        \n",
    "    return(str_copy_to_geom_full_path, str_copy_to_geom_hdf_full_path)\n",
    "# ...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b04eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++++++++++++++++++++++++++++\n",
    "def fn_get_gdf_of_cells_from_list(hdf_file_path, list_unique_indices_sorted, str_2darea_name):\n",
    "\n",
    "    # Specify the HDF5 file path and group path\n",
    "    area_2D_path = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "    str_hdf_folder_2darea = area_2D_path + str_2darea_name + '/'\n",
    "\n",
    "    # Location of Face Point Coordinates in HDF5\n",
    "    str_facepoint_coords = str_hdf_folder_2darea + 'FacePoints Coordinate'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "        # Extract X and Y coordinates\n",
    "        x_coordinates = hdf_file[str_facepoint_coords][:, 0]\n",
    "        y_coordinates = hdf_file[str_facepoint_coords][:, 1]\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df_facepoints = pd.DataFrame({'X': x_coordinates, 'Y': y_coordinates})\n",
    "\n",
    "    # Location of Indices of face points making up the cells\n",
    "    str_cells_facepoint_indexes = str_hdf_folder_2darea + 'Cells FacePoint Indexes'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "        # Extract face points coordinate data\n",
    "        facepoints_data = hdf_file[str_cells_facepoint_indexes][:]\n",
    "\n",
    "        # Extract the projection\n",
    "        projection_wkt = hdf_file.attrs['Projection'].decode('utf-8')\n",
    "\n",
    "    # Create a GeoDataFrame to store the polygons\n",
    "    geometry = []\n",
    "    indices = []\n",
    "\n",
    "    for row_idx, row in enumerate(facepoints_data):\n",
    "        polygon_coords = []\n",
    "\n",
    "        if row_idx in list_unique_indices_sorted:\n",
    "            for idx in row:\n",
    "                if idx != -1:\n",
    "                    x = df_facepoints.loc[idx, 'X']\n",
    "                    y = df_facepoints.loc[idx, 'Y']\n",
    "                    polygon_coords.append((x, y))\n",
    "            # Check if the polygon has at least 3 points (needed to create a polygon)\n",
    "            if len(polygon_coords) >= 3:\n",
    "                # Connect to the first point to close the polygon\n",
    "                polygon_coords.append(polygon_coords[0])\n",
    "                geometry.append(Polygon(polygon_coords))\n",
    "                indices.append(row_idx)  # Append the row index as the cell index\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    gdf_cells = gpd.GeoDataFrame(geometry=geometry, index=indices, columns=['geometry'], crs=projection_wkt)\n",
    "    \n",
    "    return(gdf_cells)\n",
    "# ++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcf2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "def fn_create_line_inside_polygon(shp_polygon):\n",
    "    \n",
    "    # Define your original polygon\n",
    "    #original_polygon = gdf_firehose_cell.iloc[0]['geometry']\n",
    "    original_polygon = shp_polygon\n",
    "\n",
    "    # Calculate the length of the shortest side\n",
    "    shortest_side_length = min(original_polygon.length for side in original_polygon.exterior.coords[:-1])\n",
    "\n",
    "    # Offset the polygon internally by 1% of the length of the shortest side\n",
    "    offset_distance = 0.01 * shortest_side_length\n",
    "    offset_polygon = original_polygon.buffer(-offset_distance)\n",
    "\n",
    "    # Extract the exterior boundary of the offset polygon\n",
    "    offset_exterior = offset_polygon.exterior\n",
    "\n",
    "    # Find the shortest side of the offset polygon\n",
    "    shortest_side_length = float('inf')\n",
    "    shortest_side = None\n",
    "    for i in range(len(offset_exterior.coords) - 1):\n",
    "        p1 = offset_exterior.coords[i]\n",
    "        p2 = offset_exterior.coords[i + 1]\n",
    "        length = LineString([p1, p2]).length\n",
    "        if length < shortest_side_length:\n",
    "            shortest_side_length = length\n",
    "            shortest_side = (p1, p2)\n",
    "\n",
    "    # Create a LineString representing the shortest side\n",
    "    shortest_side_line = LineString(shortest_side)\n",
    "    \n",
    "    return(shortest_side_line)\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46d9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_number_round_digits(number, int_requested_digits):\n",
    "    integer_digits = int(math.log10(abs(number))) + 1 if number != 0 else 1\n",
    "    decimal_places = max(0, int_requested_digits - integer_digits - 1)  # Ensure decimal_places is non-negative\n",
    "    formatted_number = '{:.{}f}'.format(number, decimal_places)\n",
    "    return formatted_number\n",
    "# --------------\n",
    "\n",
    "\n",
    "# --------------\n",
    "def fn_format_coords(coords, int_requested_digits):\n",
    "    formatted_coords = []\n",
    "    for pair in coords:\n",
    "        formatted_pair = []\n",
    "        for num in pair:\n",
    "            formatted_num = fn_number_round_digits(num, int_requested_digits)\n",
    "            formatted_pair.append(formatted_num)\n",
    "        formatted_coords.append(formatted_pair)\n",
    "    return formatted_coords\n",
    "# --------------\n",
    "\n",
    "\n",
    "# --------------\n",
    "def fn_midpoint(coords):\n",
    "    # this assumes only two points\n",
    "    # Extracting coordinates\n",
    "    x1, y1 = coords[0]\n",
    "    x2, y2 = coords[1]\n",
    "    \n",
    "    # Calculating midpoint\n",
    "    mid_x = (x1 + x2) / 2\n",
    "    mid_y = (y1 + y2) / 2\n",
    "    \n",
    "    return (mid_x, mid_y)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833f43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "def fn_get_index_of_bc_to_edit(str_boundary_to_edit, str_geom_path):\n",
    "    # Edit the Internal boundary condition\n",
    "    target_line = \"BC Line Name=\" + str_boundary_to_edit\n",
    "\n",
    "    # Open the file and read its content\n",
    "    with open(str_geom_path, 'r') as file:\n",
    "        list_lines = file.readlines()\n",
    "\n",
    "    # Find the index of the line starting with the target string\n",
    "    index = None\n",
    "    for i, line in enumerate(list_lines):\n",
    "        if line.startswith(target_line):\n",
    "            index = i\n",
    "            break\n",
    "\n",
    "    # Extract the following six lines into a list\n",
    "    #list_boundary_lines = list_lines[index+2:index+7]\n",
    "    return(index)\n",
    "# ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eecd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "def fn_build_internal_boundary_text(hdf_file_path, list_unique_indices_sorted, str_2d_area_name):\n",
    "    \n",
    "    gdf_firehose_cell = fn_get_gdf_of_cells_from_list(hdf_file_path, list_unique_indices_sorted, str_2d_area_name )\n",
    "\n",
    "    # Create a shapley line inside the 'source' emmiter cell\n",
    "    shp_line = fn_create_line_inside_polygon(gdf_firehose_cell.iloc[0]['geometry'])\n",
    "\n",
    "    # Create a numpy array of the the shapel line coordinates\n",
    "    coords = np.array(shp_line.coords)\n",
    "\n",
    "    tup_mid_coords = fn_midpoint(coords)\n",
    "\n",
    "    # Converting tuple to list\n",
    "    list_mid_coords = list(tup_mid_coords)\n",
    "\n",
    "    list_mid_coords_formatted = []\n",
    "    for item in list_mid_coords:\n",
    "        str_format = fn_number_round_digits(item, 16)\n",
    "        list_mid_coords_formatted.append(str_format)\n",
    "\n",
    "    # Format the boundarline coords as strings\n",
    "    formatted_coords = fn_format_coords(coords, 16)\n",
    "\n",
    "    first_pair = formatted_coords[0]\n",
    "    last_pair = formatted_coords[-1]\n",
    "    int_point_len = len(formatted_coords)\n",
    "\n",
    "    # Join the formatted coordinates into a string\n",
    "    str_start_point = 'BC Line Start Position= {} , {} \\n'.format(*first_pair)\n",
    "    str_mid_point = 'BC Line Middle Position= {} , {} \\n'.format(*list_mid_coords_formatted)\n",
    "    str_last_point = 'BC Line End Position= {} , {} \\n'.format(*last_pair)\n",
    "    str_line_arc = f'BC Line Arc= {int_point_len} \\n'\n",
    "\n",
    "    # Flatten the list of boundary condition points\n",
    "    str_point_list = [item for sublist in formatted_coords for item in sublist]\n",
    "    str_point_list += ' \\n'\n",
    "\n",
    "    # Join the elements into one continuous string\n",
    "    str_line_points = ''.join(str_point_list)\n",
    "\n",
    "    list_new_boundary_lines = [str_start_point,str_mid_point,str_last_point,str_line_arc,str_line_points]\n",
    "    \n",
    "    return(list_new_boundary_lines)\n",
    "# *****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220a5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "def fn_replace_boundary_lines_in_file(file_path, list_new_boundary_lines, index):\n",
    "    # Read the contents of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Calculate the start and end indices for replacement\n",
    "    start_index = index + 2\n",
    "    end_index = index + 7\n",
    "\n",
    "    # Perform the replacement\n",
    "    lines[start_index:end_index] = list_new_boundary_lines\n",
    "\n",
    "    # Write the modified contents back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c457f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# Function to find nearest boundary_int\n",
    "def fn_find_nearest_boundary_int(value, boundary_values):\n",
    "    nearest_boundary_int = None\n",
    "    for boundary_int in boundary_values:\n",
    "        if boundary_int <= value:\n",
    "            nearest_boundary_int = boundary_int\n",
    "        else:\n",
    "            break\n",
    "    return nearest_boundary_int\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d4c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "def fn_generate_step_integer(flt_lower_flow, flt_upper_flow, flt_delta_q):\n",
    "    integers = []\n",
    "    current = flt_lower_flow\n",
    "    if flt_upper_flow != None and flt_delta_q != None:\n",
    "        if flt_upper_flow > flt_lower_flow:\n",
    "            while current < flt_upper_flow:\n",
    "                integers.append(int(current))\n",
    "                current += flt_delta_q\n",
    "\n",
    "            # Add flt_upper_flow back if it's not in the list\n",
    "            if integers[-1] != flt_upper_flow:\n",
    "                integers.append(int(flt_upper_flow))\n",
    "        else:\n",
    "            integers.append(int(flt_lower_flow))\n",
    "    else:\n",
    "        integers.append(int(flt_lower_flow))\n",
    "    return (integers)\n",
    "# -----------------\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "def fn_create_hydrograph_lines(dict_flows):\n",
    "\n",
    "    # get flow variables from the flow dictionary\n",
    "    flt_lower_flow = dict_flows['lower_flow']\n",
    "    flt_upper_flow = dict_flows['upper_flow']\n",
    "    flt_delta_q = dict_flows['delta_q']\n",
    "    int_hour_count = dict_flows['hour_count']\n",
    "    \n",
    "    list_flow_rows = []\n",
    "\n",
    "    # get a list of flow steps\n",
    "    list_flow_steps_int = fn_generate_step_integer(flt_lower_flow, flt_upper_flow, flt_delta_q)\n",
    "\n",
    "    list_flows = []\n",
    "    for item in list_flow_steps_int:\n",
    "        for i in range(int_hour_count):\n",
    "            list_flows.append(item)\n",
    "\n",
    "    # Calculate the number of groups of 10\n",
    "    int_groups_of_10 = len(list_flows) // 10\n",
    "\n",
    "    # Calculate the remainder\n",
    "    int_remainder = len(list_flows) % 10\n",
    "\n",
    "    str_first_line = f\"Flow Hydrograph= {len(list_flows)} \\n\"\n",
    "    list_flow_rows.append(str_first_line)\n",
    "\n",
    "    for i in range(int_groups_of_10):\n",
    "        #print(i)\n",
    "        list_current_row = list_flows[i*10:i*10+10]\n",
    "\n",
    "        str_current_row = \"\"\n",
    "        for item in list_current_row:\n",
    "            # (8 characters with right justified with padding)\n",
    "            str_flow = str(item).rjust(8)\n",
    "            str_current_row += str_flow\n",
    "        str_current_row += '\\n'\n",
    "\n",
    "        list_flow_rows.append(str_current_row)\n",
    "\n",
    "    list_last_row = list_flows[int_groups_of_10*10:]\n",
    "    str_current_row = \"\"\n",
    "    for item in list_last_row:\n",
    "        # (8 characters with right justified with padding)\n",
    "        str_flow = str(item).rjust(8)\n",
    "        str_current_row += str_flow\n",
    "    str_current_row += '\\n'\n",
    "    list_flow_rows.append(str_current_row)\n",
    "\n",
    "    return(list_flow_rows, len(list_flows))\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a25c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "def fn_copy_unsteady_flow_file(list_proj_title_files, int_u_to_copy, dict_flows):\n",
    "    # determine the unsteady flow files that are in the project\n",
    "\n",
    "    list_unsteady_names = fn_list_filename_from_ras_prj(list_proj_title_files[0],\"Unsteady File=\")\n",
    "    list_unsteady_int = fn_extract_numbers_from_strings(list_unsteady_names)\n",
    "\n",
    "    # Splitting the path into folder and filename\n",
    "    str_prj_folder, str_filename = os.path.split(list_proj_title_files[0])\n",
    "\n",
    "    # Splitting the filename and its extension\n",
    "    str_file_only, str_extension = os.path.splitext(str_filename)\n",
    "\n",
    "    list_unsteady_fullpath = []\n",
    "\n",
    "    for unsteady_item in list_unsteady_names:\n",
    "        str_unsteady_file = str_file_only + \".\" + unsteady_item\n",
    "\n",
    "        # Combine the folder path and filename\n",
    "        str_unsteady_full_path = os.path.join(str_prj_folder, str_unsteady_file)\n",
    "\n",
    "        list_unsteady_fullpath.append(str_unsteady_full_path)\n",
    "\n",
    "    list_b_unsteady_exists = fn_list_of_file_exists(list_unsteady_fullpath)\n",
    "\n",
    "    # Assuming all lists have the same length\n",
    "    data = {\n",
    "        'unsteady_int': list_unsteady_int,\n",
    "        'unsteady_name': list_unsteady_names,\n",
    "        'unsteady_path': list_unsteady_fullpath,\n",
    "        'unsteady_exists': list_b_unsteady_exists,\n",
    "    }\n",
    "\n",
    "    df_unsteady = pd.DataFrame(data)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df_unsteady[(df_unsteady['unsteady_int'] == int_u_to_copy) & (df_unsteady['unsteady_exists'])]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_filtered.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Unsteady Flow Match Found')\n",
    "\n",
    "        # Determine the highest number in unsteady_int\n",
    "        highest_u_int = df_unsteady['unsteady_int'].max()\n",
    "\n",
    "        # Add one to the highest number\n",
    "        next_u_int = highest_u_int + 1\n",
    "\n",
    "        # Convert next_u_int to string with leading zero padding if necessary\n",
    "        next_u_int_str = '{:02d}'.format(next_u_int)\n",
    "\n",
    "        # copy geom file\n",
    "        str_copy_from = df_filtered.iloc[0]['unsteady_path']\n",
    "        str_copy_to_u = str_file_only + \".u\" + next_u_int_str\n",
    "        str_copy_to_u_full_path = os.path.join(str_prj_folder, str_copy_to_u)\n",
    "\n",
    "        shutil.copy(str_copy_from, str_copy_to_u_full_path)\n",
    "        print(f\"Copied {str_copy_from} to {str_copy_to_u_full_path}\")\n",
    "\n",
    "        # ------------------\n",
    "        # Add the new unsteady file to the HEC-RAS project\n",
    "\n",
    "        # Read the contents of the file\n",
    "        with open(list_proj_title_files[0], 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the last occurrence of a line starting with \"Geom File=\"\n",
    "        last_u_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].strip().startswith(\"Unsteady File=\"):\n",
    "                last_u_index = i\n",
    "\n",
    "        # Insert a new line after the last occurrence of \"Geom File=\"\n",
    "        if last_u_index != -1:\n",
    "            lines.insert(last_u_index + 1, \"Unsteady File=u\" + next_u_int_str + \"\\n\")\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(list_proj_title_files[0], 'w') as file:\n",
    "            file.writelines(lines)\n",
    "    \n",
    "    # Determine where the boundary conditions begin\n",
    "    if not os.path.exists(str_copy_to_u_full_path):\n",
    "        print(f\"File {str_copy_to_u_full_path} not found.\")\n",
    "    else:\n",
    "        # Open the file and read its content\n",
    "        with open(str_copy_to_u_full_path, \"r\") as file:\n",
    "            # Read lines from the file\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Find indices and lines that start with \"Boundary Location=\"\n",
    "            matching_indices_and_lines = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Boundary Location=', line)]\n",
    "\n",
    "            # Extract only the indices\n",
    "            list_matching_indices = [index for index, _ in matching_indices_and_lines]\n",
    "\n",
    "            # extract the lines text\n",
    "            list_boundary_location_line = [value  for _, value in matching_indices_and_lines]\n",
    "\n",
    "            # Extracting the seventh value 'Boundary Name' from each row\n",
    "            list_boundary_names = [row.split(',')[7].strip() for row in list_boundary_location_line]\n",
    "\n",
    "            # Create a df for the boundary condition rows\n",
    "            data = {\n",
    "                'boundary_int': list_matching_indices,\n",
    "                'boundary_name': list_boundary_names\n",
    "            }\n",
    "\n",
    "            df_boundary = pd.DataFrame(data)\n",
    "            \n",
    "    with open(str_copy_to_u_full_path, \"r\") as file:\n",
    "        # Read lines from the file\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Find indices and lines that start with \"Boundary Location=\" --- list of tuples\n",
    "        list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Flow Hydrograph=', line)]\n",
    "        \n",
    "    # Create new columns\n",
    "    df_boundary['is_hydro'] = False\n",
    "    df_boundary['hydro_int_start'] = None\n",
    "    df_boundary['hydro_count_int'] = None\n",
    "\n",
    "    # Finding nearest boundary_int for each item in list_tup_match\n",
    "    for item in list_tup_match:\n",
    "        value_to_match = item[0]\n",
    "        hydro_count_int = int(item[1].split('=')[-1])  # Parsing hydro_count_int from the second value in the tuple\n",
    "        nearest_boundary_int = fn_find_nearest_boundary_int(value_to_match, df_boundary['boundary_int'])\n",
    "        if nearest_boundary_int is not None:\n",
    "            df_boundary.loc[df_boundary['boundary_int'] == nearest_boundary_int, 'is_hydro'] = True\n",
    "            df_boundary.loc[df_boundary['boundary_int'] == nearest_boundary_int, 'hydro_int_start'] = value_to_match\n",
    "            df_boundary.loc[df_boundary['boundary_int'] == nearest_boundary_int, 'hydro_count_int'] = hydro_count_int\n",
    "            \n",
    "    # determine the rows to delete from the original unsteady flow file\n",
    "    df_inflow_rows = df_boundary[df_boundary['boundary_name'] == str_boundary_to_edit]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_inflow_rows.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Boundary Condition Found')\n",
    "\n",
    "        # TODO - grab the first row from df and determine rows to remove\n",
    "\n",
    "        # Grab the first row\n",
    "        first_row = df_inflow_rows.iloc[0]\n",
    "\n",
    "        # Access the \"hydro_int_start\" and \"hydro_count_int\" columns\n",
    "        hydro_int_start = first_row['hydro_int_start']\n",
    "        hydro_count_int = first_row['hydro_count_int']\n",
    "\n",
    "        # Determine number of rows to delete\n",
    "\n",
    "        # Calculate the number of groups of 10\n",
    "        int_rows_to_delete = hydro_count_int // 10 + 2\n",
    "    \n",
    "    # get the unsteady flow rows and hours to simulate\n",
    "    list_flow_rows, int_sim_time_hr = fn_create_hydrograph_lines(dict_flows)\n",
    "    \n",
    "    # Update the flow hydrograph for the selected boundary condition\n",
    "    with open(str_copy_to_u_full_path, \"r\") as file:\n",
    "        # Read lines from the file\n",
    "        lines = file.readlines()\n",
    "\n",
    "        int_end_index = hydro_int_start + int_rows_to_delete\n",
    "\n",
    "        # Delete the rows from hydro_int_start to end_index\n",
    "        del lines[hydro_int_start:int_end_index]\n",
    "\n",
    "        # Insert lines from list_flow_rows at hydro_int_start index\n",
    "        lines[hydro_int_start:hydro_int_start] = list_flow_rows\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_u_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    # Enforce a 1HOUR Interval (\"Inverval=1HOUR\") in the unsteady flow file\n",
    "\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_u_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find indices and lines that start with \"Boundary Location=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Interval=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Interval=1HOUR\\n\"  # Replace the line with \"Interval=1HOUR\"\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_u_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    # --------------------- \n",
    "    # Change the name of the Unsteady Flow Title\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_u_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    str_run_name = dict_flows['run_name']\n",
    "    \n",
    "    # Find indices and lines that start with \"Flow Title=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Flow Title=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Flow Title=\" + str_run_name + '_unsteady_flow' + \"\\n\"\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_u_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    return(str_copy_to_u_full_path, int_sim_time_hr)\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdd2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "def fn_copy_plan_file(list_proj_title_files, int_p_to_copy,\n",
    "                      next_geom_int_str, next_u_int_str,\n",
    "                      dict_flows):\n",
    "\n",
    "    # determine the geometry files that are in the project\n",
    "    list_plan_names = fn_list_filename_from_ras_prj(list_proj_title_files[0], \"Plan File=\")\n",
    "    list_plan_int = fn_extract_numbers_from_strings(list_plan_names)\n",
    "\n",
    "    # Splitting the path into folder and filename\n",
    "    str_prj_folder, str_filename = os.path.split(list_proj_title_files[0])\n",
    "\n",
    "    # Splitting the filename and its extension\n",
    "    str_file_only, str_extension = os.path.splitext(str_filename)\n",
    "\n",
    "    list_plan_fullpath = []\n",
    "\n",
    "    for plan_item in list_plan_names:\n",
    "        str_plan_file = str_file_only + \".\" + plan_item\n",
    "\n",
    "        # Combine the folder path and filename\n",
    "        str_plan_full_path = os.path.join(str_prj_folder, str_plan_file)\n",
    "\n",
    "        list_plan_fullpath.append(str_plan_full_path)\n",
    "\n",
    "    list_b_plan_exists = fn_list_of_file_exists(list_plan_fullpath)\n",
    "\n",
    "    # Assuming all lists have the same length\n",
    "    data = {\n",
    "        'plan_int': list_plan_int,\n",
    "        'plan_name': list_plan_names,\n",
    "        'plan_path': list_plan_fullpath,\n",
    "        'plan_exists': list_b_plan_exists,\n",
    "    }\n",
    "\n",
    "    df_plan = pd.DataFrame(data)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df_plan[(df_plan['plan_int'] == int_p_to_copy) & (df_plan['plan_exists'])]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_filtered.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Plan Match Found')\n",
    "\n",
    "        # Determine the highest number in plan_int\n",
    "        highest_p_int = df_plan['plan_int'].max()\n",
    "\n",
    "        # Add one to the highest number\n",
    "        next_p_int = highest_p_int + 1\n",
    "\n",
    "        # Convert next_p_int to string with leading zero padding if necessary\n",
    "        next_p_int_str = '{:02d}'.format(next_p_int)\n",
    "\n",
    "        # copy plan file\n",
    "        str_copy_from = df_filtered.iloc[0]['plan_path']\n",
    "        str_copy_to_p = str_file_only + \".p\" + next_p_int_str\n",
    "        str_copy_to_p_full_path = os.path.join(str_prj_folder, str_copy_to_p)\n",
    "\n",
    "        shutil.copy(str_copy_from, str_copy_to_p_full_path)\n",
    "        print(f\"Copied {str_copy_from} to {str_copy_to_p_full_path}\")\n",
    "\n",
    "        # ------------------\n",
    "        # Add the new plan file to the HEC-RAS project\n",
    "\n",
    "        # Read the contents of the file\n",
    "        with open(list_proj_title_files[0], 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the last occurrence of a line starting with \"Plan File=\"\n",
    "        last_p_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].strip().startswith(\"Plan File=\"):\n",
    "                last_p_index = i\n",
    "\n",
    "        # Insert a new line after the last occurrence of \"Plan File=\"\n",
    "        if last_p_index != -1:\n",
    "            lines.insert(last_p_index + 1, \"Plan File=p\" + next_p_int_str + \"\\n\")\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(list_proj_title_files[0], 'w') as file:\n",
    "            file.writelines(lines)\n",
    "\n",
    "    # ---------------------\n",
    "    # Within the plan file, adjust the selected geometry file\n",
    "\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_p_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find indices and lines that start with \"Geom File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Geom File=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Geom File=g\" + next_geom_int_str + \"\\n\"\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_p_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    # ---------------------\n",
    "    # Within the plan file, adjust the selected unsteady file\n",
    "\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_p_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find indices and lines that start with \"Flow File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Flow File=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Flow File=u\" + next_u_int_str + \"\\n\"\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_p_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    # ---------------------\n",
    "    # Within the plan file, change the plan \n",
    "\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_p_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # --- Append the plan title in the plan file\n",
    "    # Find indices and lines that start with \"Flow File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Plan Title=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Plan Title=\" + dict_flows['run_name'] + \"_plan\" + \"\\n\"\n",
    "\n",
    "    # --- Append the short identifier in the plan file\n",
    "    # Find indices and lines that start with \"Flow File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Short Identifier=', line)]  \n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Short Identifier=\" + dict_flows['short_name'] + \"\\n\"\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_p_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    return(str_copy_to_p_full_path)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea670ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "def fn_generate_simulation_date_string(start_date_str, hours):\n",
    "    \n",
    "    # The first hour is the \"zero-th\" hour\n",
    "    hours = hours - 1\n",
    "    \n",
    "    # Convert start_date_str to a datetime object\n",
    "    start_date = datetime.strptime(start_date_str, '%d%b%Y')\n",
    "\n",
    "    # Calculate end date by adding hours to the start date\n",
    "    end_date = start_date + timedelta(hours=hours)\n",
    "\n",
    "    # Format dates to the required string format\n",
    "    start_date_formatted = start_date.strftime('%d%b%Y,%H%M')\n",
    "    end_date_formatted = end_date.strftime('%d%b%Y,%H%M')\n",
    "\n",
    "    # Concatenate start and end date strings\n",
    "    date_string = f\"{start_date_formatted},{end_date_formatted}\"\n",
    "\n",
    "    return date_string\n",
    "# ---------------\n",
    "\n",
    "# ***************\n",
    "def fn_set_plan_simulation_date_range(str_copy_to_p_full_path,\n",
    "                                      str_simulation_start_date,\n",
    "                                      int_sim_time_hr):\n",
    "\n",
    "    # In the plan file, set the simulation date range\n",
    "\n",
    "    # Read the file content\n",
    "    with open(str_copy_to_p_full_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find indices and lines that start with \"Geom File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Simulation Date=', line)]\n",
    "\n",
    "    str_simulation_range = fn_generate_simulation_date_string(str_simulation_start_date, int_sim_time_hr)\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Simulation Date=\" + str_simulation_range + \"\\n\"  # Replace Simulation Date\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(str_copy_to_p_full_path, \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "# ***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a62c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_set_active_plan(list_proj_title_files, next_p_int_str):\n",
    "    # Set the newly created plan to current in the project file.\n",
    "\n",
    "    # Read the file content\n",
    "    with open(list_proj_title_files[0], 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find indices and lines that start with \"Geom File=\"\n",
    "    list_tup_match = [(index, line.strip()) for index, line in enumerate(lines) if re.match(r'^Current Plan=', line)]\n",
    "\n",
    "    # Replace lines in the list\n",
    "    for index, _ in list_tup_match:\n",
    "        lines[index] = \"Current Plan=p\" + next_p_int_str + \"\\n\"  # Replace Simulation Date\n",
    "\n",
    "    # Write the modified lines back to the file\n",
    "    with open(list_proj_title_files[0], \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086bc182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid HEC-RAS Project: E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.prj\n",
      "Valid Geometry Match Found\n",
      "Copied E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g01 to E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g39\n",
      "Copied E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g01.hdf to E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g39.hdf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dict_flows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- ---\u001b[39;00m\n\u001b[0;32m      8\u001b[0m list_proj_title_files \u001b[38;5;241m=\u001b[39m fn_list_of_ras_projects(str_ras_path)\n\u001b[1;32m----> 9\u001b[0m str_geom_path, hdf_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mfn_copy_geom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_proj_title_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_geom_to_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m index \u001b[38;5;241m=\u001b[39m fn_get_index_of_bc_to_edit(str_boundary_to_edit, str_geom_path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ---- example input: gdf_mainstems.iloc[17] ----\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 115\u001b[0m, in \u001b[0;36mfn_copy_geom_file\u001b[1;34m(list_proj_title_files, int_geom_to_copy)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Replace lines in the list\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, _ \u001b[38;5;129;01min\u001b[39;00m list_tup_match:\n\u001b[1;32m--> 115\u001b[0m     lines[index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeom Title=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mdict_flows\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_geom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Write the modified lines back to the file\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(str_copy_to_geom_full_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_flows' is not defined"
     ]
    }
   ],
   "source": [
    "# This is the main body script\n",
    "\n",
    "# --- Read the geopackage ---\n",
    "gdf_area = gpd.read_file(str_model_hydrofabric_gpkg, layer='00_area_2d')\n",
    "gdf_mainstems = gpd.read_file(str_model_hydrofabric_gpkg, layer='03_flowpaths_stabilize')\n",
    "# --- ---\n",
    "\n",
    "# ---- example input: gdf_mainstems.iloc[17] ----\n",
    "dict_mainstem = gdf_mainstems.iloc[17].to_dict()\n",
    "int_idx_start_cell = int(dict_mainstem['idx_start_cell'])\n",
    "list_unique_indices_sorted = [int_idx_start_cell]\n",
    "\n",
    "dict_area_2d = gdf_area.iloc[0].to_dict()\n",
    "str_2d_area_name = dict_area_2d['area_2d_name']\n",
    "\n",
    "# --- Time for single flow to run ---\n",
    "int_hour_count = int(dict_mainstem['travel_time_hr']) + 1 + int_time_rolling_avg + int_buffer_time\n",
    "dict_mainstem['time_sim_hr'] = int_hour_count\n",
    "\n",
    "# create the run names (note: set flt_upper_flow to None for single flow simulation)\n",
    "str_run_name,str_short_name = fn_build_plan_names(flt_lower_flow, flt_upper_flow, dict_mainstem)\n",
    "\n",
    "# Convert the flow data to dictionary\n",
    "dict_flows = {\n",
    "    \"lower_flow\": flt_lower_flow,\n",
    "    \"upper_flow\": flt_upper_flow,\n",
    "    \"delta_q\": flt_delta_q,\n",
    "    \"hour_count\": int_hour_count,\n",
    "    \"run_name\": str_run_name,\n",
    "    \"short_name\": str_short_name\n",
    "}\n",
    "\n",
    "list_proj_title_files = fn_list_of_ras_projects(str_ras_path)\n",
    "str_geom_path, hdf_file_path = fn_copy_geom_file(list_proj_title_files, int_geom_to_copy, dict_flows)\n",
    "\n",
    "index = fn_get_index_of_bc_to_edit(str_boundary_to_edit, str_geom_path)\n",
    "\n",
    "# Create the text to insert as boundary condition \n",
    "list_new_boundary_lines = fn_build_internal_boundary_text(hdf_file_path, list_unique_indices_sorted, str_2d_area_name)\n",
    "\n",
    "# replace boundary condition lines in file\n",
    "fn_replace_boundary_lines_in_file(str_geom_path, list_new_boundary_lines, index)\n",
    "\n",
    "# copy the unsteady flow file\n",
    "str_copy_to_u_full_path, int_sim_time_hr = fn_copy_unsteady_flow_file(list_proj_title_files, int_u_to_copy, dict_flows)\n",
    "\n",
    "# --- inputs for plan file creation ---\n",
    "next_geom_int_str = os.path.splitext(str_geom_path)[1][2:]\n",
    "next_u_int_str = os.path.splitext(str_copy_to_u_full_path)[1][2:] \n",
    "# --- ---\n",
    "\n",
    "# copy the plan flow file and modify\n",
    "str_copy_to_p_full_path = fn_copy_plan_file(list_proj_title_files, int_p_to_copy,\n",
    "                                            next_geom_int_str, next_u_int_str,\n",
    "                                            dict_flows)\n",
    "\n",
    "fn_set_plan_simulation_date_range(str_copy_to_p_full_path,\n",
    "                                  str_simulation_start_date,\n",
    "                                  int_sim_time_hr)\n",
    "\n",
    "# --- input to set the active plan ---\n",
    "next_p_int_str = os.path.splitext(str_copy_to_p_full_path)[1][2:]\n",
    "# --- ---\n",
    "\n",
    "fn_set_active_plan(list_proj_title_files, next_p_int_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa033635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - 2024.05.11 -- Instead of copy gXX, pXX, uXX to the same RAS project... create a new prj?\n",
    "# TODO - 2024.05.11 -- rename the geometry file with long name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c0d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
