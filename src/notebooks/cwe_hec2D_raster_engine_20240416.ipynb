{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c7607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Revised - 2024.04.17\n",
    "# Create flood products from HEC-RAS 2D output\n",
    "\n",
    "import h5py\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, box, mapping, shape\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.features import shapes\n",
    "\n",
    "import rasterio.mask\n",
    "\n",
    "from osgeo import gdal, gdalconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the HDF file\n",
    "hdf_file_path = r'E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.p02.hdf'\n",
    "str_dem_path = r'E:\\HECRAS_2D_12070205\\BLE_12070205_Engineering_Models\\Engineering Models\\Hydraulic Models\\RAS_Submittal\\LBSG_501\\Input\\Terrain\\Terrain4.DEM_3.tif'\n",
    "\n",
    "# Specify the path where you want to save the GeoPackage file\n",
    "input_gpkg = r'E:\\sample_2d_output\\sample_flooded_cells.gpkg'\n",
    "\n",
    "str_dem_output_folder = r'E:\\working\\large_dem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41a21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the \n",
    "# Read the GeoPackage file\n",
    "gdf_cells_wsel = gpd.read_file(input_gpkg, layer='02_cells_wsel')\n",
    "\n",
    "# Get unique values of 'cell_idx' and sort them\n",
    "list_unique_indices_sorted = sorted(gdf_cells_wsel['cell_idx'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9620442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "def fn_get_group_names(hdf5_file_path, group_path):\n",
    "    \"\"\"\n",
    "    Retrieve the names of groups within a specified HDF5 file under a given group path.\n",
    "\n",
    "    Parameters:\n",
    "    hdf5_file_path (str): The file path to the HDF5 file.\n",
    "    group_path (str): The path to the group whose subgroups' names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    list or None: A list containing the names of groups found under the specified group path. \n",
    "                  Returns None if the group path does not exist in the HDF5 file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "            # Check if the specified group path exists\n",
    "            if group_path in hdf_file:\n",
    "                group = hdf_file[group_path]\n",
    "\n",
    "                # Extract names of HDF5 Group objects\n",
    "                group_names = [name for name in group if isinstance(group[name], h5py.Group)]\n",
    "\n",
    "                return group_names\n",
    "            else:\n",
    "                print(f\"Group '{group_path}' not found in the HDF5 file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64eb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the HDF5 file path and group path\n",
    "group_path = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "# Get names of HDF5 Group objects in the specified group\n",
    "list_group_names = fn_get_group_names(hdf_file_path, group_path)\n",
    "\n",
    "# for now... lets assume that there is only one 2D area\n",
    "str_cell_info_path = '/Geometry/2D Flow Areas/Cell Info'\n",
    "\n",
    "str_cell_center_point_path = group_path + list_group_names[0] + '/' + 'Cells Center Coordinate'\n",
    "\n",
    "# From the plan HDF, get the cells center coordinates (not the centroid)\n",
    "with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "    arr_cell_center_coords = hdf_file[str_cell_center_point_path][:]\n",
    "    \n",
    "# Filter the array to those cells that are wet\n",
    "arr_center_coords_wet_cells = arr_cell_center_coords[list_unique_indices_sorted]\n",
    "\n",
    "geometry = [Point(x, y) for x, y in arr_center_coords_wet_cells]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf_center_points = gpd.GeoDataFrame(geometry=geometry, columns=['geometry'], crs=gdf_cells_wsel.crs)\n",
    "\n",
    "# create a new coloumn that contains the cell index\n",
    "gdf_center_points['cell_idx'] = list_unique_indices_sorted\n",
    "\n",
    "# from geodataframe, create dataframe from only the 'cell_idx' and 'wsel' coloumns\n",
    "df_wsel = gdf_cells_wsel[['cell_idx', 'wsel']]\n",
    "\n",
    "# left join the WSEL per cell to pobulate the geodataframe of cells with WSEL\n",
    "gdf_wsel_wet_cells = pd.merge(gdf_center_points, df_wsel, on='cell_idx', how='left')\n",
    "\n",
    "# set constant arbitraty value used to disolve geometry\n",
    "gdf_cells_wsel['val'] = 1\n",
    "\n",
    "# create a geodataframe of the merged cells\n",
    "gdf_dissolved = gdf_cells_wsel.dissolve(by='val')\n",
    "\n",
    "# get shapely geometry of the first merged polygon\n",
    "shp_wet_cells = gdf_dissolved.geometry.iloc[0]\n",
    "\n",
    "# Convert Shapely polygon to GeoJSON-like format\n",
    "geom = mapping(shp_wet_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df51f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the resolution of the ground DEM\n",
    "# Open the raster file\n",
    "dataset = gdal.Open(str_dem_path)\n",
    "\n",
    "# Get raster resolution\n",
    "flt_pixel_width = dataset.GetGeoTransform()[1]\n",
    "\n",
    "# Close the dataset raster file\n",
    "dataset = None  # Release the reference to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c698d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_wsel_wet_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed73fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the points in gdf_wsel_wet_cells wrap a convex hull\n",
    "# Check each cell's polygon (gdf_cells_wsel) faces.  If the center of that cells face is not within the convex hull\n",
    "# then create a point at the center of that face.  If there are duplicate points on the same spot, average the\n",
    "# wsel value of these spots and drop\n",
    "\n",
    "# TODO -2 024.04.16 -  maybe this should be vertex and note center point\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "# -------------\n",
    "def fn_compute_convex_hull(points):\n",
    "    hull = ConvexHull(points)\n",
    "    return [points[vertex] for vertex in hull.vertices]\n",
    "\n",
    "def fn_calculate_vertex_points(polygon):\n",
    "    list_points = []\n",
    "    coords = polygon.exterior.coords\n",
    "    num_coords = len(coords)\n",
    "    for i in range(num_coords):  # Iterate over vertex\n",
    "        x, y = coords[i]\n",
    "        list_points.append(Point(x, y))\n",
    "    return list_points\n",
    "\n",
    "def fn_is_point_inside_convex_hull(point, hull_points):\n",
    "    hull_polygon = Polygon(hull_points)\n",
    "    return hull_polygon.contains(point)\n",
    "\n",
    "# Define a function to merge points within a certain distance threshold\n",
    "def merge_points_within_threshold(gdf, threshold):\n",
    "    merged_points = []\n",
    "    grouped = gdf.groupby(gdf.geometry.apply(lambda x: (round(x.x, 2), round(x.y, 2))))\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            merged_point = Point(group.geometry.x.mean(), group.geometry.y.mean())\n",
    "            avg_wsel = group['wsel'].mean()  # Calculate the average of 'wsel' column\n",
    "            merged_points.append({'geometry': merged_point, 'wsel': avg_wsel})\n",
    "        else:\n",
    "            merged_points.append({'geometry': group.iloc[0].geometry, 'wsel': group.iloc[0]['wsel']})\n",
    "    \n",
    "    return gpd.GeoDataFrame(merged_points)\n",
    "# -------------\n",
    "\n",
    "# List to store created points\n",
    "created_points = []\n",
    "list_cell_wsel = []\n",
    "\n",
    "# Wrap Convex Hull\n",
    "convex_hull_points = fn_compute_convex_hull(gdf_wsel_wet_cells.geometry.apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "# Iterate through cell polygons and perform checks\n",
    "for _, cell_polygon in gdf_cells_wsel.iterrows():\n",
    "    vertex_points = fn_calculate_vertex_points(cell_polygon.geometry)\n",
    "    for v_point in vertex_points:\n",
    "        if not fn_is_point_inside_convex_hull(v_point, convex_hull_points):\n",
    "            created_points.append(v_point)\n",
    "            list_cell_wsel.append(cell_polygon['wsel'])\n",
    "\n",
    "# Create a new GeoDataFrame from created points\n",
    "gdf_additional_points = gpd.GeoDataFrame(geometry=created_points)\n",
    "\n",
    "gdf_additional_points['wsel'] = list_cell_wsel\n",
    "gdf_additional_points.crs = gdf_wsel_wet_cells.crs\n",
    "\n",
    "# Remove the duplicate points... that sit on two cells\n",
    "# Set the distance threshold\n",
    "threshold_distance = 0.01  # in feet\n",
    "\n",
    "# Merge points within the threshold distance\n",
    "gdf_additional_points_duplicates_removed = merge_points_within_threshold(gdf_additional_points, threshold_distance)\n",
    "\n",
    "gdf_additional_points_duplicates_removed.crs = gdf_wsel_wet_cells.crs\n",
    "\n",
    "\n",
    "points1 = gdf_wsel_wet_cells[['geometry', 'wsel']].copy()\n",
    "\n",
    "if len(gdf_additional_points_duplicates_removed) > 0:\n",
    "    points2 = gdf_additional_points_duplicates_removed[['geometry', 'wsel']].copy()\n",
    "    points = pd.concat([points1, points2], axis=0)\n",
    "else:\n",
    "    points = points1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7710092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the points of computed wsel\n",
    "x = points.geometry.x.values\n",
    "y = points.geometry.y.values\n",
    "z = points['wsel'].values\n",
    "\n",
    "# Define the extent of the cell point raster\n",
    "xmin, ymin, xmax, ymax = gdf_dissolved.total_bounds\n",
    "x_res = flt_pixel_width  # resolution in x direction\n",
    "y_res = flt_pixel_width  # resolution in y direction\n",
    "\n",
    "# Create the grid\n",
    "xi = np.arange(xmin, xmax, x_res)\n",
    "yi = np.arange(ymin, ymax, y_res)\n",
    "xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "# Perform bilinear interpolation\n",
    "zi = griddata((x, y), z, (xi, yi), method='linear')\n",
    "\n",
    "# Define the affine transformation\n",
    "transform = Affine.translation(xmin, ymin) * Affine.scale(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Begin the creation of the raster products\n",
    "list_raster_to_purge = []\n",
    "\n",
    "# Define output raster file path\n",
    "output_raster_path_01 = os.path.join(str_dem_output_folder,'01_wsel_interp.tif')\n",
    "\n",
    "# Write the interpolated raster to a GeoTIFF file\n",
    "with rasterio.open(output_raster_path_01, 'w', driver='GTiff', height=zi.shape[0], width=zi.shape[1], count=1,\n",
    "                   dtype=zi.dtype,\n",
    "                   crs=gdf_wsel_wet_cells.crs,\n",
    "                   transform=transform) as dst:\n",
    "    dst.write(zi, 1)\n",
    "    \n",
    "list_raster_to_purge.append(output_raster_path_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4089240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Shapely polygon to GeoJSON-like format\n",
    "geom = mapping(shp_wet_cells)\n",
    "\n",
    "# Open the raster dataset in read mode\n",
    "with rasterio.open(output_raster_path_01, 'r') as dst:\n",
    "\n",
    "    # Mask the interpolated raster with the polygon\n",
    "    zi_masked, transform_masked = rasterio.mask.mask(dst, [geom], crop=True, nodata=np.nan)  # Specify nodata value as np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24543c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output masked raster file path\n",
    "# Define output raster file path\n",
    "output_masked_raster_path_02 = os.path.join(str_dem_output_folder,'02_wsel_interp_masked.tif')\n",
    "\n",
    "# Write the masked interpolated raster to a GeoTIFF file\n",
    "with rasterio.open(output_masked_raster_path_02, 'w', driver='GTiff', height=zi_masked.shape[1], width=zi_masked.shape[2], count=1,\n",
    "                   dtype=zi_masked.dtype,\n",
    "                   crs=gdf_wsel_wet_cells.crs,\n",
    "                   transform=transform_masked,\n",
    "                   nodata=np.nan) as dst_masked:  # Specify nodata value as np.nan\n",
    "    dst_masked.write(zi_masked[0], 1)\n",
    "    \n",
    "list_raster_to_purge.append(output_masked_raster_path_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b99206",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Open and read the first raster\n",
    "    with rasterio.open(output_masked_raster_path_02) as src1:\n",
    "        raster1 = src1.read(1)\n",
    "        transform1 = src1.transform\n",
    "        crs1 = src1.crs\n",
    "        \n",
    "        try:\n",
    "            # Open and read the second raster (ground dem raster)\n",
    "            with rasterio.open(str_dem_path) as src2:\n",
    "                raster2 = src2.read(1)\n",
    "                transform2 = src2.transform\n",
    "                crs2 = src2.crs\n",
    "\n",
    "                # Get common extent\n",
    "                bbox = gpd.GeoDataFrame(geometry=[box(*src1.bounds), box(*src2.bounds)], crs=crs1)\n",
    "                common_extent = bbox.unary_union.bounds\n",
    "\n",
    "                # Resample and align rasters\n",
    "                dst_crs = crs1\n",
    "                transform, width, height = calculate_default_transform(crs2, dst_crs, src2.width, src2.height, *src2.bounds)\n",
    "                kwargs = src2.meta.copy()\n",
    "                kwargs.update({\n",
    "                    'crs': dst_crs,\n",
    "                    'transform': transform,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "\n",
    "                raster2_aligned = np.zeros_like(raster1)\n",
    "                reproject(\n",
    "                    source=raster2,\n",
    "                    destination=raster2_aligned,\n",
    "                    src_transform=src2.transform,\n",
    "                    src_crs=src2.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest)\n",
    "\n",
    "                # Clip rasters\n",
    "                output_raster_path_03 = os.path.join(str_dem_output_folder,'03_wsel_interp_mask_align.tif')\n",
    "                output_raster_path_04 = os.path.join(str_dem_output_folder,'04_ground_align.tif')\n",
    "                \n",
    "                with rasterio.open(output_raster_path_03, 'w', **src1.meta) as dst1:\n",
    "                    out_img1, out_transform1 = mask(src1, [bbox.iloc[0]['geometry']], crop=True)\n",
    "                    dst1.write(out_img1)\n",
    "\n",
    "                with rasterio.open(output_raster_path_04, 'w', **src2.meta) as dst2:\n",
    "                    out_img2, out_transform2 = mask(src2, [bbox.iloc[1]['geometry']], crop=True)\n",
    "                    dst2.write(out_img2)\n",
    "                    \n",
    "                list_raster_to_purge.append(output_raster_path_03)\n",
    "                list_raster_to_purge.append(output_raster_path_04)\n",
    "\n",
    "        except rasterio.errors.RasterioIOError as e:\n",
    "            print(\"Error opening or processing raster file:\", e)\n",
    "        \n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "    print(\"Error opening raster file:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f1f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "def fn_raster_subtraction(raster1_path, raster2_path, output_folder):\n",
    "    \n",
    "    list_created_rasters = []\n",
    "    \n",
    "    # Open the first raster\n",
    "    raster1 = gdal.Open(raster1_path, gdalconst.GA_ReadOnly)\n",
    "    if raster1 is None:\n",
    "        raise FileNotFoundError(f\"Raster not found at {raster1_path}\")\n",
    "\n",
    "    # Open the second raster\n",
    "    raster2 = gdal.Open(raster2_path, gdalconst.GA_ReadOnly)\n",
    "    if raster2 is None:\n",
    "        raise FileNotFoundError(f\"Raster not found at {raster2_path}\")\n",
    "\n",
    "    # Get the extent and resolution of the first raster\n",
    "    x_min, pixel_width, _, y_max, _, pixel_height = raster1.GetGeoTransform()\n",
    "    x_max = x_min + raster1.RasterXSize * pixel_width\n",
    "    y_min = y_max + raster1.RasterYSize * pixel_height\n",
    "\n",
    "    # Resample the second raster to match the extent and resolution of the first raster\n",
    "    #resampled_raster2_path = r'E:\\working\\05_ground_resampled_align.tif'\n",
    "    resampled_raster2_path = os.path.join(output_folder,'05_ground_resampled_align.tif')\n",
    "    \n",
    "    gdal.Warp(resampled_raster2_path, raster2, format='GTiff', outputBounds=[x_min, y_min, x_max, y_max], xRes=pixel_width, yRes=pixel_height)\n",
    "\n",
    "    # Perform raster subtraction\n",
    "    raster1_data = raster1.ReadAsArray()\n",
    "    resampled_raster2 = gdal.Open(resampled_raster2_path, gdalconst.GA_ReadOnly)\n",
    "    resampled_raster2_data = resampled_raster2.ReadAsArray()\n",
    "\n",
    "    result_data = raster1_data - resampled_raster2_data\n",
    "\n",
    "    # Create output raster\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    output_raster_path_06 = os.path.join(output_folder,'06_depth.tif')\n",
    "    output_raster = driver.Create(output_raster_path_06, raster1.RasterXSize, raster1.RasterYSize, 1, gdalconst.GDT_Float32)\n",
    "\n",
    "    # Set projection and transform\n",
    "    output_raster.SetProjection(raster1.GetProjection())\n",
    "    output_raster.SetGeoTransform(raster1.GetGeoTransform())\n",
    "\n",
    "    # TODO - 2024.02.23 -- likely writing two raster bands\n",
    "    # Write result data to output raster\n",
    "    output_band = output_raster.GetRasterBand(1)\n",
    "    output_band.WriteArray(result_data)\n",
    "\n",
    "    # Close rasters\n",
    "    output_band = None\n",
    "    output_raster = None\n",
    "    raster1 = None\n",
    "    resampled_raster2 = None\n",
    "    \n",
    "    list_created_rasters.append(output_raster_path_06)\n",
    "    \n",
    "    return(list_created_rasters)\n",
    "# -------------------\n",
    "\n",
    "# Perform raster subtraction\n",
    "list_created_rasters = fn_raster_subtraction(output_raster_path_03, output_raster_path_04, str_dem_output_folder)\n",
    "\n",
    "# Append the items in list_created_raster to list_raster_to_purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0bec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the raster file paths\n",
    "output_raster_path_06 = os.path.join(str_dem_output_folder,'06_depth.tif')\n",
    "output_raster_path_07 = os.path.join(str_dem_output_folder,'07_depth_with_nan.tif')\n",
    "\n",
    "with rasterio.open(output_raster_path_06, 'r') as src:\n",
    "    # Read raster data\n",
    "    data = src.read(1)\n",
    "\n",
    "    # Set values less than zero to NaN\n",
    "    data[data < 0] = float('nan')\n",
    "\n",
    "    # Copy metadata\n",
    "    kwargs = src.meta.copy()\n",
    "\n",
    "    # Update metadata for the new file\n",
    "    kwargs.update(dtype=rasterio.float32)\n",
    "\n",
    "    # Write the modified data to a new GeoTIFF file\n",
    "    with rasterio.open(output_raster_path_07, 'w', **kwargs) as dst:\n",
    "        dst.write(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df6a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "def fn_raster_addition_wsel(ground_raster_path, depth_raster_path, output_folder):\n",
    "\n",
    "    # Open the GeoTIFF rasters\n",
    "    ground_raster = gdal.Open(ground_raster_path)\n",
    "    depth_raster = gdal.Open(depth_raster_path)\n",
    "\n",
    "    # Read raster data as NumPy arrays\n",
    "    ground_data = ground_raster.ReadAsArray()\n",
    "    depth_data = depth_raster.ReadAsArray()\n",
    "\n",
    "    # Convert depth data to float, as NaN is a floating-point concept\n",
    "    depth_data = depth_data.astype(float)\n",
    "\n",
    "    # Mask NaN values in depth data\n",
    "    depth_data[np.isnan(depth_data)] = np.nan\n",
    "\n",
    "    # Add the two rasters where depth is not NaN\n",
    "    result = np.where(~np.isnan(depth_data), ground_data + depth_data, np.nan)\n",
    "\n",
    "    # Save the result to a new GeoTIFF\n",
    "    \n",
    "    output_path = os.path.join(output_folder, '08_wsel_with_nan.tif')\n",
    "    \n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    output_raster = driver.Create(output_path, ground_raster.RasterXSize, ground_raster.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    output_raster.SetProjection(ground_raster.GetProjection())\n",
    "    output_raster.SetGeoTransform(ground_raster.GetGeoTransform())\n",
    "    output_band = output_raster.GetRasterBand(1)\n",
    "    output_band.WriteArray(result)\n",
    "    output_band.FlushCache()\n",
    "\n",
    "    # Close the rasters\n",
    "    ground_raster = None\n",
    "    depth_raster = None\n",
    "    output_raster = None\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc627b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_raster_path_05 = os.path.join(str_dem_output_folder,'05_ground_resampled_align.tif')\n",
    "\n",
    "fn_raster_addition_wsel(output_raster_path_05, output_raster_path_07, str_dem_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833b2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "def fn_make_floodplain_gdf(str_input_raster_filepath, flt_minvalue, flt_max_value):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts a raster file representing flooded areas to a GeoDataFrame of a single MultiPolygon representing the floodplain.\n",
    "\n",
    "    Parameters:\n",
    "    - str_input_raster_filepath (str): File path of the input raster file.\n",
    "    - flt_downscale_size (float): Resolution to which the raster should be downscaled.\n",
    "    - flt_minvalue (float): minimum value of depth allowed\n",
    "    - flt_max_value (float): maximum value of depth allowed\n",
    "\n",
    "    Returns:\n",
    "    - gdf_single_floodplain (geopandas.GeoDataFrame): GeoDataFrame containing a merged MultiPolygon representing the floodplain.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------\n",
    "    # open the raster file and convert to 'binary' of flooded=1 and null = 255\n",
    "    with rasterio.open(str_input_raster_filepath) as src:\n",
    "        # Read the raster data as a numpy array\n",
    "        data = src.read(1)\n",
    "\n",
    "        # Set values greater than flt_minvalue and <= flt_max_value to 1, others to 255\n",
    "        data = np.where((data > flt_minvalue) & (data <= flt_max_value), 1, 255).astype('uint8')\n",
    "\n",
    "\n",
    "        # Create a new raster file with the updated data type and nodata value\n",
    "        profile = src.profile\n",
    "        profile.update(dtype=rasterio.uint8, nodata=255)\n",
    "\n",
    "        # Use in-memory storage\n",
    "        output_raster_memory = rasterio.MemoryFile()\n",
    "        with output_raster_memory.open(**profile) as dst:\n",
    "            dst.write(data, 1)\n",
    "\n",
    "        #print(\"Conversion completed. Output raster stored in memory.\")\n",
    "\n",
    "    # ----------------------\n",
    "    # convert the downscaled binary raster to geodataframe of polygons\n",
    "    # Open the input GeoTIFF file\n",
    "    with output_raster_memory.open() as src:\n",
    "        # Read the raster data\n",
    "        data = src.read(1, masked=True)  # using masked=True to handle NoData as a mask\n",
    "\n",
    "        # Set all non-null values to 1\n",
    "        data = np.where(data.mask, 255, 1).astype('uint8')\n",
    "\n",
    "        # Extract shapes from the raster data\n",
    "        shapes_gen = shapes(data, mask=data != 255, transform=src.transform)\n",
    "\n",
    "        # Convert shapes to Shapely geometries and create a GeoDataFrame\n",
    "        geometries = [shape(geom) for geom, _ in shapes_gen]\n",
    "        gdf = gpd.GeoDataFrame(geometry=geometries, crs=src.crs)\n",
    "\n",
    "    # Merge all polygons into a single MultiPolygon\n",
    "    merged_polygon = gdf['geometry'].unary_union\n",
    "\n",
    "    # Create a new GeoDataFrame with the merged MultiPolygon\n",
    "    gdf_single_floodplain = gpd.GeoDataFrame(geometry=[merged_polygon], crs=gdf.crs)\n",
    "\n",
    "    # Close downscaled_raster_memory to release the memory\n",
    "    output_raster_memory.close()\n",
    "\n",
    "    return(gdf_single_floodplain)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ea33474",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_minvalue = 0\n",
    "flt_max_value = 10000\n",
    "\n",
    "gdf_floodplain = fn_make_floodplain_gdf(output_raster_path_07, flt_minvalue, flt_max_value)\n",
    "\n",
    "# Specify the file path where you want to save the shapefile\n",
    "output_shapefile = os.path.join(str_dem_output_folder,'09_floodplain_ar.gpkg')\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf_floodplain.to_file(output_shapefile, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a042cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp - create a point geopackage of the points for wsel interpolation\n",
    "output_path = os.path.join(str_dem_output_folder,'10_cell_pnts.gpkg')\n",
    "\n",
    "gdf_wsel_wet_cells.to_file(output_path, layer='01_hecras_cells_pnt', driver=\"GPKG\")\n",
    "gdf_additional_points.to_file(output_path, layer='02_additional_vertex_pnt', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e5a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_created_rasters:\n",
    "    list_raster_to_purge.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762dbd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'E:\\working\\large_dem\\01_wsel_interp.tif' deleted successfully.\n",
      "File 'E:\\working\\large_dem\\02_wsel_interp_masked.tif' deleted successfully.\n",
      "File 'E:\\working\\large_dem\\03_wsel_interp_mask_align.tif' deleted successfully.\n",
      "File 'E:\\working\\large_dem\\04_ground_align.tif' deleted successfully.\n",
      "File 'E:\\working\\large_dem\\06_depth.tif' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Probably want to keep 5(ground), 7(depth) & 8(wsel)\n",
    "\n",
    "for file_path in list_raster_to_purge:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File '{file_path}' deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting file '{file_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36016b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
