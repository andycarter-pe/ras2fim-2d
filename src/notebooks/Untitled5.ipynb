{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cef5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf548bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Constants from config file ----\n",
    "str_boundary_to_edit = \"Emitter1\"\n",
    "\n",
    "# average time lookback to determine cells wsel 'stability' in hours\n",
    "int_time_rolling_avg = 4\n",
    "\n",
    "# additional time to extend run (in hours)\n",
    "int_buffer_time = 5\n",
    "\n",
    "# low flow in cfs for stability runs\n",
    "flt_base_flow = 500\n",
    "\n",
    "# model hydrofabric geopackage\n",
    "str_model_hydrofabric_gpkg = r'E:\\sample_2d_output\\BLE_LBSG_501_p02\\model_hydrofabric.gpkg'\n",
    "\n",
    "# directory containing the HEC-RAS files to spawn new runs/geometry\n",
    "str_ras_path = r'E:\\HECRAS_2D_12070205\\base_model_20240414_copy'\n",
    "\n",
    "int_geom_to_copy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f69fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "def fn_format_flow_as_string(flt_flow):\n",
    "    # format a flow value to no more than 5 characters\n",
    "    # if bigger than 100000 ... returns 1.0e5\n",
    "    \n",
    "    # works up to 990 million cfs\n",
    "    if flt_flow >= 100000:\n",
    "        formatted_flow = \"{:.1e}\".format(flt_flow)\n",
    "        parts = formatted_flow.split('e')\n",
    "        formatted_flow = \"{}e{}\".format(parts[0], int(parts[1]))  # Reconstructing the notation\n",
    "        if len(formatted_flow) > 8:  # Ensuring the total length is 8 characters\n",
    "            formatted_flow = \"{:.1e}\".format(flt_flow).replace(\"e\", \"e+\")\n",
    "    else:\n",
    "        formatted_flow = str(flt_flow)\n",
    "    \n",
    "    # returns a string\n",
    "    return(formatted_flow)\n",
    "# ---------------\n",
    "\n",
    "# --------------------\n",
    "def fn_list_filename_from_ras_prj(str_ras_prj_path, str_line_header):\n",
    "    # Open the file\n",
    "    with open(list_proj_title_files[0], 'r') as file:\n",
    "        # Read lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Initialize a list to store File values\n",
    "        list_names = []\n",
    "\n",
    "        # Iterate through each line\n",
    "        for line in lines:\n",
    "            # Check if the line contains \"Unsteady File\"\n",
    "            if str_line_header in line:\n",
    "                # Extract the value after \"Unsteady File=\"\n",
    "                value = line.split(str_line_header)[1].strip()\n",
    "                # Add the value to the list\n",
    "                list_names.append(value)\n",
    "        return(list_names)\n",
    "# --------------------\n",
    "\n",
    "# ----------\n",
    "def fn_extract_numbers_from_strings(lst):\n",
    "    numbers = []\n",
    "    for item in lst:\n",
    "        number = re.search(r'\\d+', item).group()\n",
    "        numbers.append(int(number))\n",
    "    return numbers\n",
    "# ----------\n",
    "\n",
    "# --------------\n",
    "def fn_list_of_file_exists(list_filepaths):\n",
    "    \n",
    "    list_b_return = []\n",
    "    for filepath in list_filepaths:\n",
    "        if os.path.exists(filepath):\n",
    "            list_b_return.append(True)\n",
    "        else:\n",
    "            list_b_return.append(False)\n",
    "    return(list_b_return)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef41bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the geopackage\n",
    "gdf_area = gpd.read_file(str_model_hydrofabric_gpkg, layer='00_area_2d')\n",
    "gdf_streams = gpd.read_file(str_model_hydrofabric_gpkg, layer='01_stream_lines')\n",
    "gdf_mainstems = gpd.read_file(str_model_hydrofabric_gpkg, layer='03_flowpaths_stabilize')\n",
    "\n",
    "# create a simulation time col in gdf_mainstems\n",
    "gdf_mainstems['time_sim_hr'] = gdf_mainstems['travel_time_hr'].astype(int) + 1 + int_time_rolling_avg + int_buffer_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9188335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_build_plan_names(flt_lower_flow, flt_upper_flow, dict_mainstem):\n",
    "    str_run_name, str_short_plan = None, None\n",
    "    \n",
    "    # systematic naming of plans (if only one flow, flt_upper_flow should be None)\n",
    "    is_single_flow = False\n",
    "    \n",
    "    try:\n",
    "        if flt_upper_flow == None:\n",
    "            is_single_flow = True\n",
    "            \n",
    "        str_mainstem = str(int(dict_mainstem['mainstem']))\n",
    "        str_start_node = dict_mainstem['id_start_node']\n",
    "        int_firehose_time = int(dict_mainstem['time_sim_hr'])\n",
    "        str_flow =  str(int(flt_lower_flow))\n",
    "\n",
    "        str_run_name = str_mainstem + \"_\" + str_start_node + \"_\" + str(int_firehose_time) + \"-\" + \"hr\"\n",
    "        str_run_name += \"_\" + str(int(flt_lower_flow)) + \"-cfs\"\n",
    "\n",
    "        if not is_single_flow:  \n",
    "            # add the upper range flow to the description\n",
    "            str_run_name += \"_to_\" + str(int(flt_upper_flow)) + \"-cfs\"\n",
    "\n",
    "        str_short_plan = str_start_node + '-' + fn_format_flow_as_string(flt_lower_flow)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return(str_run_name, str_short_plan)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42fcb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in gdf_mainstems.iterrows():\n",
    "    a,b = fn_build_plan_names(flt_base_flow, None, row.to_dict())\n",
    "    #print(a)\n",
    "    #print(b)\n",
    "    #print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dda1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "def fn_list_of_ras_projects(str_ras_path):\n",
    "\n",
    "    list_proj_title_files = []\n",
    "\n",
    "    # locate the valid HEC-RAS project\n",
    "    try:\n",
    "        list_prj_files = [os.path.join(str_ras_path, f) for f in os.listdir(str_ras_path) if f.endswith('.prj')]\n",
    "\n",
    "        if len(list_prj_files) > 0:\n",
    "            list_proj_title_files = []\n",
    "\n",
    "            for file_path in list_prj_files:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    contents = file.read()\n",
    "                    if 'Proj Title' in contents:\n",
    "                        list_proj_title_files.append(file_path)\n",
    "\n",
    "            for file_path in list_proj_title_files:\n",
    "                print(f\"Valid HEC-RAS Project: {file_path}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"No HEC-RAS PRJ found in {str_ras_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    return(list_proj_title_files)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177687de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ....................\n",
    "def fn_copy_geom_file(list_proj_title_files, int_geom_to_copy):\n",
    "    \n",
    "    str_copy_to_geom_full_path = None\n",
    "    str_copy_to_geom_hdf_full_path = None\n",
    "\n",
    "    # Splitting the path into folder and filename\n",
    "    str_prj_folder, str_filename = os.path.split(list_proj_title_files[0])\n",
    "\n",
    "    # Splitting the filename and its extension\n",
    "    str_file_only, str_extension = os.path.splitext(str_filename)\n",
    "\n",
    "    # determine the geometry files that are in the project\n",
    "    list_geom_names = fn_list_filename_from_ras_prj(list_proj_title_files[0], \"Geom File=\")\n",
    "    list_geom_int = fn_extract_numbers_from_strings(list_geom_names)\n",
    "\n",
    "    list_geom_hdf_fullpath = []\n",
    "    list_geom_fullpath = []\n",
    "\n",
    "    for geom_item in list_geom_names:\n",
    "        str_hdf_geom_file = str_file_only + \".\" + geom_item + \".hdf\"\n",
    "        str_geom_file = str_file_only + \".\" + geom_item\n",
    "\n",
    "        # Combine the folder path and filename\n",
    "        str_hdf_full_path = os.path.join(str_prj_folder, str_hdf_geom_file)\n",
    "        str_geom_full_path = os.path.join(str_prj_folder, str_geom_file)\n",
    "\n",
    "        list_geom_hdf_fullpath.append(str_hdf_full_path)\n",
    "        list_geom_fullpath.append(str_geom_full_path)\n",
    "\n",
    "    list_b_hdf_exists = []\n",
    "\n",
    "    list_b_hdf_exists = fn_list_of_file_exists(list_geom_hdf_fullpath)\n",
    "    list_b_geom_exists = fn_list_of_file_exists(list_geom_fullpath)\n",
    "\n",
    "    # Assuming all lists have the same length\n",
    "    data = {\n",
    "        'geom_int': list_geom_int,\n",
    "        'geom_name': list_geom_names,\n",
    "        'hdf_path': list_geom_hdf_fullpath,\n",
    "        'hdf_exists': list_b_hdf_exists,\n",
    "        'geom_path': list_geom_fullpath,\n",
    "        'geom_exists': list_b_geom_exists\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df[(df['geom_int'] == int_geom_to_copy) & (df['hdf_exists']) & (df['geom_exists'])]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_filtered.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Geometry Match Found')\n",
    "\n",
    "        # Determine the highest number in geom_int\n",
    "        highest_geom_int = df['geom_int'].max()\n",
    "\n",
    "        # Add one to the highest number\n",
    "        next_geom_int = highest_geom_int + 1\n",
    "\n",
    "        # Convert next_geom_int to string with leading zero padding if necessary\n",
    "        next_geom_int_str = '{:02d}'.format(next_geom_int)\n",
    "\n",
    "        # copy geom file\n",
    "        str_copy_from = df_filtered.iloc[0]['geom_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str\n",
    "        str_copy_to_geom_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from, str_copy_to_geom_full_path)\n",
    "        print(f\"Copied {str_copy_from} to {str_copy_to_geom_full_path}\")\n",
    "\n",
    "        # copy the hdf geom file\n",
    "        str_copy_from_hdf = df_filtered.iloc[0]['hdf_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str + \".hdf\"\n",
    "        str_copy_to_geom_hdf_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from_hdf, str_copy_to_geom_hdf_full_path)\n",
    "        print(f\"Copied {str_copy_from_hdf} to {str_copy_to_geom_hdf_full_path}\")\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~\n",
    "        # add the geom to the project file\n",
    "\n",
    "        # Read the contents of the file\n",
    "        with open(list_proj_title_files[0], 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the last occurrence of a line starting with \"Geom File=\"\n",
    "        last_geom_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].strip().startswith(\"Geom File=\"):\n",
    "                last_geom_index = i\n",
    "\n",
    "        # Insert a new line after the last occurrence of \"Geom File=\"\n",
    "        if last_geom_index != -1:\n",
    "            lines.insert(last_geom_index + 1, \"Geom File=g\" + next_geom_int_str + \"\\n\")\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(list_proj_title_files[0], 'w') as file:\n",
    "            file.writelines(lines)\n",
    "\n",
    "    else:\n",
    "        # Otherwise, print an error statement\n",
    "        print(\"Error: Geometry HDF and gXX not available.\")\n",
    "        \n",
    "    return(str_copy_to_geom_full_path, str_copy_to_geom_hdf_full_path)\n",
    "# ...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c3c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++++++++++++++++++++++++++++\n",
    "def fn_get_gdf_of_cells_from_list(hdf_file_path, list_unique_indices_sorted, str_2darea_name):\n",
    "\n",
    "    # Specify the HDF5 file path and group path\n",
    "    area_2D_path = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "    str_hdf_folder_2darea = area_2D_path + str_2darea_name + '/'\n",
    "\n",
    "    # Location of Face Point Coordinates in HDF5\n",
    "    str_facepoint_coords = str_hdf_folder_2darea + 'FacePoints Coordinate'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "        # Extract X and Y coordinates\n",
    "        x_coordinates = hdf_file[str_facepoint_coords][:, 0]\n",
    "        y_coordinates = hdf_file[str_facepoint_coords][:, 1]\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df_facepoints = pd.DataFrame({'X': x_coordinates, 'Y': y_coordinates})\n",
    "\n",
    "    # Location of Indices of face points making up the cells\n",
    "    str_cells_facepoint_indexes = str_hdf_folder_2darea + 'Cells FacePoint Indexes'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "        # Extract face points coordinate data\n",
    "        facepoints_data = hdf_file[str_cells_facepoint_indexes][:]\n",
    "\n",
    "        # Extract the projection\n",
    "        projection_wkt = hdf_file.attrs['Projection'].decode('utf-8')\n",
    "\n",
    "    # Create a GeoDataFrame to store the polygons\n",
    "    geometry = []\n",
    "    indices = []\n",
    "\n",
    "    for row_idx, row in enumerate(facepoints_data):\n",
    "        polygon_coords = []\n",
    "\n",
    "        if row_idx in list_unique_indices_sorted:\n",
    "            for idx in row:\n",
    "                if idx != -1:\n",
    "                    x = df_facepoints.loc[idx, 'X']\n",
    "                    y = df_facepoints.loc[idx, 'Y']\n",
    "                    polygon_coords.append((x, y))\n",
    "            # Check if the polygon has at least 3 points (needed to create a polygon)\n",
    "            if len(polygon_coords) >= 3:\n",
    "                # Connect to the first point to close the polygon\n",
    "                polygon_coords.append(polygon_coords[0])\n",
    "                geometry.append(Polygon(polygon_coords))\n",
    "                indices.append(row_idx)  # Append the row index as the cell index\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    gdf_cells = gpd.GeoDataFrame(geometry=geometry, index=indices, columns=['geometry'], crs=projection_wkt)\n",
    "    \n",
    "    return(gdf_cells)\n",
    "# ++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ff9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "def fn_create_line_inside_polygon(shp_polygon):\n",
    "    \n",
    "    # Define your original polygon\n",
    "    original_polygon = gdf_firehose_cell.iloc[0]['geometry']\n",
    "\n",
    "    # Calculate the length of the shortest side\n",
    "    shortest_side_length = min(original_polygon.length for side in original_polygon.exterior.coords[:-1])\n",
    "\n",
    "    # Offset the polygon internally by 1% of the length of the shortest side\n",
    "    offset_distance = 0.01 * shortest_side_length\n",
    "    offset_polygon = original_polygon.buffer(-offset_distance)\n",
    "\n",
    "    # Extract the exterior boundary of the offset polygon\n",
    "    offset_exterior = offset_polygon.exterior\n",
    "\n",
    "    # Find the shortest side of the offset polygon\n",
    "    shortest_side_length = float('inf')\n",
    "    shortest_side = None\n",
    "    for i in range(len(offset_exterior.coords) - 1):\n",
    "        p1 = offset_exterior.coords[i]\n",
    "        p2 = offset_exterior.coords[i + 1]\n",
    "        length = LineString([p1, p2]).length\n",
    "        if length < shortest_side_length:\n",
    "            shortest_side_length = length\n",
    "            shortest_side = (p1, p2)\n",
    "\n",
    "    # Create a LineString representing the shortest side\n",
    "    shortest_side_line = LineString(shortest_side)\n",
    "    \n",
    "    return(shortest_side_line)\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f124e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_number_round_digits(number, int_requested_digits):\n",
    "    integer_digits = int(math.log10(abs(number))) + 1 if number != 0 else 1\n",
    "    decimal_places = max(0, int_requested_digits - integer_digits - 1)  # Ensure decimal_places is non-negative\n",
    "    formatted_number = '{:.{}f}'.format(number, decimal_places)\n",
    "    return formatted_number\n",
    "# --------------\n",
    "\n",
    "\n",
    "# --------------\n",
    "def fn_format_coords(coords, int_requested_digits):\n",
    "    formatted_coords = []\n",
    "    for pair in coords:\n",
    "        formatted_pair = []\n",
    "        for num in pair:\n",
    "            formatted_num = fn_number_round_digits(num, int_requested_digits)\n",
    "            formatted_pair.append(formatted_num)\n",
    "        formatted_coords.append(formatted_pair)\n",
    "    return formatted_coords\n",
    "# --------------\n",
    "\n",
    "\n",
    "# --------------\n",
    "def fn_midpoint(coords):\n",
    "    # this assumes only two points\n",
    "    # Extracting coordinates\n",
    "    x1, y1 = coords[0]\n",
    "    x2, y2 = coords[1]\n",
    "    \n",
    "    # Calculating midpoint\n",
    "    mid_x = (x1 + x2) / 2\n",
    "    mid_y = (y1 + y2) / 2\n",
    "    \n",
    "    return (mid_x, mid_y)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b44e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid HEC-RAS Project: E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.prj\n",
      "Valid Geometry Match Found\n",
      "Copied E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g01 to E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g08\n",
      "Copied E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g01.hdf to E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.g08.hdf\n"
     ]
    }
   ],
   "source": [
    "list_proj_title_files = fn_list_of_ras_projects(str_ras_path)\n",
    "str_geom_path, hdf_file_path = fn_copy_geom_file(list_proj_title_files, int_geom_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26500e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the Internal boundary condition\n",
    "target_line = \"BC Line Name=\" + str_boundary_to_edit\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(str_geom_path, 'r') as file:\n",
    "    list_lines = file.readlines()\n",
    "\n",
    "# Find the index of the line starting with the target string\n",
    "index = None\n",
    "for i, line in enumerate(list_lines):\n",
    "    if line.startswith(target_line):\n",
    "        index = i\n",
    "        break\n",
    "\n",
    "\n",
    "# Extract the following six lines into a list\n",
    "list_boundary_lines = list_lines[index+2:index+7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25cf621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BC Line Start Position= 2979518.67298034 , 10258382.7677894 \\n',\n",
       " 'BC Line Middle Position= 2979059.69353878 , 10257459.6518339 \\n',\n",
       " 'BC Line End Position= 2978600.71409721 , 10256536.5358783 \\n',\n",
       " 'BC Line Arc= 2 \\n',\n",
       " '2979518.6729803410258382.76778942978600.7140972110256536.5358783\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_boundary_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb2a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mainstem = gdf_mainstems.iloc[17].to_dict()\n",
    "int_idx_start_cell = int(dict_mainstem['idx_start_cell'])\n",
    "list_unique_indices_sorted = [int_idx_start_cell]\n",
    "\n",
    "dict_area_2d = gdf_area.iloc[0].to_dict()\n",
    "str_2d_area_name = dict_area_2d['area_2d_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0fa4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "def fn_build_internal_boundary_text(hdf_file_path, list_unique_indices_sorted, str_2d_area_name):\n",
    "    gdf_firehose_cell = fn_get_gdf_of_cells_from_list(hdf_file_path, list_unique_indices_sorted, str_2d_area_name )\n",
    "\n",
    "    # Create a shapley line inside the 'source' emmiter cell\n",
    "    shp_line = fn_create_line_inside_polygon(gdf_firehose_cell.iloc[0]['geometry'])\n",
    "\n",
    "    # Create a numpy array of the the shapel line coordinates\n",
    "    coords = np.array(shp_line.coords)\n",
    "\n",
    "    tup_mid_coords = fn_midpoint(coords)\n",
    "\n",
    "    # Converting tuple to list\n",
    "    list_mid_coords = list(tup_mid_coords)\n",
    "\n",
    "    list_mid_coords_formatted = []\n",
    "    for item in list_mid_coords:\n",
    "        str_format = fn_number_round_digits(item, 16)\n",
    "        list_mid_coords_formatted.append(str_format)\n",
    "\n",
    "    # Format the boundarline coords as strings\n",
    "    formatted_coords = fn_format_coords(coords, 16)\n",
    "\n",
    "    first_pair = formatted_coords[0]\n",
    "    last_pair = formatted_coords[-1]\n",
    "    int_point_len = len(formatted_coords)\n",
    "\n",
    "    # Join the formatted coordinates into a string\n",
    "    str_start_point = 'BC Line Start Position= {} , {} \\n'.format(*first_pair)\n",
    "    str_mid_point = 'BC Line Middle Position= {} , {} \\n'.format(*list_mid_coords_formatted)\n",
    "    str_last_point = 'BC Line End Position= {} , {} \\n'.format(*last_pair)\n",
    "    str_line_arc = f'BC Line Arc= {int_point_len} \\n'\n",
    "\n",
    "    # Flatten the list of boundary condition points\n",
    "    str_point_list = [item for sublist in formatted_coords for item in sublist]\n",
    "    str_point_list += ' \\n'\n",
    "\n",
    "    # Join the elements into one continuous string\n",
    "    str_line_points = ''.join(str_point_list)\n",
    "\n",
    "    list_new_boundary_lines = [str_start_point,str_mid_point,str_last_point,str_line_arc,str_line_points]\n",
    "    \n",
    "    return(list_new_boundary_lines)\n",
    "# *****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40bbe5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_new_boundary_lines = fn_build_internal_boundary_text(hdf_file_path, list_unique_indices_sorted, str_2d_area_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e60003a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BC Line Start Position= 3028536.82550507 , 10258145.7856357 \\n',\n",
       " 'BC Line Middle Position= 3028496.27205166 , 10258138.0573055 \\n',\n",
       " 'BC Line End Position= 3028455.71859825 , 10258130.3289753 \\n',\n",
       " 'BC Line Arc= 2 \\n',\n",
       " '3028536.8255050710258145.78563573028455.7185982510258130.3289753 \\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_new_boundary_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
