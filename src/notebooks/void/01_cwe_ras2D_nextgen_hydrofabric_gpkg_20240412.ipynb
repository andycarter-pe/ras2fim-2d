{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c84968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geopackage of the stream network for the HEC-RAS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77412d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, box, mapping, shape\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb085dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "hdf_file_path = r'E:\\HECRAS_2D_12070205\\BLE_12070205_Engineering_Models\\Engineering Models\\Hydraulic Models\\RAS_Submittal\\LBSG_501\\Input\\BLE_LBSG_501.p02.hdf'\n",
    "gpkg_nextgen_path = r'E:\\ras2fim-2d\\nextgen-test\\nextgen_12.gpkg'\n",
    "\n",
    "# Specify the path where you want to save the GeoPackage file\n",
    "output_path = r'E:\\sample_2d_output\\model_hydrofabric.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe3d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "def fn_get_group_names(hdf5_file_path, group_path):\n",
    "    \"\"\"\n",
    "    Retrieve the names of groups within a specified HDF5 file under a given group path.\n",
    "\n",
    "    Parameters:\n",
    "    hdf5_file_path (str): The file path to the HDF5 file.\n",
    "    group_path (str): The path to the group whose subgroups' names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    list or None: A list containing the names of groups found under the specified group path. \n",
    "                  Returns None if the group path does not exist in the HDF5 file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "            # Check if the specified group path exists\n",
    "            if group_path in hdf_file:\n",
    "                group = hdf_file[group_path]\n",
    "\n",
    "                # Extract names of HDF5 Group objects\n",
    "                group_names = [name for name in group if isinstance(group[name], h5py.Group)]\n",
    "\n",
    "                return group_names\n",
    "            else:\n",
    "                print(f\"Group '{group_path}' not found in the HDF5 file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddad2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "def get_gdf_of_2d_area(hdf_file_path):\n",
    "\n",
    "    # Specify the HDF5 file path and group path\n",
    "    str_hdf_geom_path = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "    # Get names of HDF5 Group objects in the specified group\n",
    "    list_group_names = fn_get_group_names(hdf_file_path, str_hdf_geom_path)\n",
    "\n",
    "    b_has_2d_area = False\n",
    "\n",
    "    if len(list_group_names) > 1:\n",
    "        print('Multiple 2D areas found -- Using first area:', list_group_names[0])\n",
    "        b_has_2d_area = True\n",
    "    elif len(list_group_names) == 0:\n",
    "        print('Error: No 2D areas found')\n",
    "    else:\n",
    "        # Only one 2D area found\n",
    "        b_has_2d_area = True\n",
    "\n",
    "    if b_has_2d_area:\n",
    "        str_perimeter_points = str_hdf_geom_path + list_group_names[0] + '/' + 'Perimeter'\n",
    "\n",
    "        # Open the HDF file\n",
    "        with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "            arr_perim_points = hdf_file[str_perimeter_points][:]\n",
    "\n",
    "            # Extract the projection\n",
    "            projection_wkt = hdf_file.attrs['Projection'].decode('utf-8')\n",
    "\n",
    "            str_terrain_filename = hdf_file['/Geometry/'].attrs['Terrain Filename'].decode('utf-8')\n",
    "\n",
    "        # Convert the array of perimeter points into a Polygon\n",
    "        shp_polygon_geom = Polygon(arr_perim_points)\n",
    "\n",
    "        # Create a GeoDataFrame\n",
    "        gdf_2d_area_polygon = gpd.GeoDataFrame(index=[0], crs=projection_wkt, geometry=[shp_polygon_geom])\n",
    "        \n",
    "        gdf_2d_area_polygon['area_2d_name'] = list_group_names[0]\n",
    "        gdf_2d_area_polygon['hdf_path'] = hdf_file_path\n",
    "        gdf_2d_area_polygon['terrain_path'] = str_terrain_filename\n",
    "        gdf_2d_area_polygon['prj_wkt_ras_model'] = projection_wkt\n",
    "        \n",
    "        return(gdf_2d_area_polygon)\n",
    "    else:\n",
    "        pass\n",
    "        # return nothing as there is nothing to return\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d11c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "def fn_extract_flowpaths_gdf(gdf_2d_area_polygon, gpkg_nextgen_path):\n",
    "\n",
    "    # From the 2d area, get the nextgen hydrofabric\n",
    "    print('Reading Nextgen Hydrofabric ~5 seconds...')\n",
    "\n",
    "    # Read the nextgen hydrofabric\n",
    "    gdf_flowpaths = gpd.read_file(gpkg_nextgen_path, layer='flowpaths')\n",
    "\n",
    "    gdf_2d_area_polygon_nextgen = gdf_2d_area_polygon.to_crs(gdf_flowpaths.crs)\n",
    "\n",
    "    # Extract the first polygon\n",
    "    shp_first_poly = gdf_2d_area_polygon_nextgen.geometry.iloc[0]\n",
    "\n",
    "    # Get the bounding box coordinates\n",
    "    bbox = shp_first_poly.bounds\n",
    "\n",
    "    # Create a bounding box geometry using the CRS of the GeoPackage\n",
    "    bbox_geom = box(*bbox)\n",
    "    \n",
    "    # Filter lines within the bounding box\n",
    "    gdf_ln_within_bbox = gdf_flowpaths[gdf_flowpaths.geometry.intersects(bbox_geom)]\n",
    "\n",
    "    # Get just the stream lines that are within or intersect the 2d area\n",
    "    gdf_ln_within_2d_area = gdf_ln_within_bbox[gdf_ln_within_bbox.geometry.within(shp_first_poly) | gdf_ln_within_bbox.geometry.intersects(shp_first_poly)]\n",
    "\n",
    "    # Get a unique list of 'id' from gdf_ln_within_2d_area\n",
    "    list_unique_ids = gdf_ln_within_2d_area['id'].unique().tolist()\n",
    "\n",
    "    # Read the GeoPackage file to get the 'flowpath_attributes' table\n",
    "    gdf_flowpath_attrib = gpd.read_file(gpkg_nextgen_path, layer='flowpath_attributes')\n",
    "\n",
    "    # Select rows where 'id' is in list_unique_ids\n",
    "    gdf_attrib_flowpath_2darea = gdf_flowpath_attrib[gdf_flowpath_attrib['id'].isin(list_unique_ids)]\n",
    "\n",
    "    # Specify the columns to keep\n",
    "    columns_to_keep = ['id', 'rl_gages', 'rl_NHDWaterbodyComID', 'So', 'ChSlp']\n",
    "\n",
    "    # Drop all columns except the specified ones\n",
    "    gdf_attrib_flowpath_2darea_subset = gdf_attrib_flowpath_2darea[columns_to_keep]\n",
    "\n",
    "    # Perform left join on 'id' to add the selecte attributes\n",
    "    gdf_flowpath_with_attrib = gdf_ln_within_2d_area.merge(gdf_attrib_flowpath_2darea_subset, on='id', how='left')\n",
    "\n",
    "    # Check if each line in gdf_flowpath_with_attrib is entirely within the polygon\n",
    "    gdf_flowpath_with_attrib['within_2darea'] = gdf_flowpath_with_attrib.geometry.within(gdf_2d_area_polygon_nextgen.iloc[0].geometry)\n",
    "    \n",
    "    return(gdf_flowpath_with_attrib)\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8257671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "def fn_create_upstream_flowpath_points(gdf_flowpath_with_attrib, gdf_2d_area_polygon_nextgen):\n",
    "\n",
    "    # get a point that is at the upstream end of every flowpath\n",
    "\n",
    "    # Create an empty list to store the points\n",
    "    list_upstream_points = []\n",
    "\n",
    "    # Iterate over each geometry in the GeoDataFrame\n",
    "    list_id = []\n",
    "\n",
    "    for index,row in gdf_flowpath_with_attrib.iterrows():\n",
    "\n",
    "        geom_items = row['geometry']\n",
    "        list_id.append(row['id'])\n",
    "\n",
    "        for geom in geom_items:\n",
    "            # Check if the geometry is a LineString or MultiLineString\n",
    "            if geom.geom_type == 'LineString':\n",
    "                endpoint = Point(geom.coords[0])  # Get the beginning of the LineString\n",
    "                list_upstream_points.append(endpoint)\n",
    "            elif geom.geom_type == 'MultiLineString':\n",
    "                for part in geom:\n",
    "                    endpoint = Point(part.coords[0])  # Get the beginning of each part\n",
    "                    list_upstream_points.append(endpoint)\n",
    "\n",
    "    # Create a new GeoDataFrame from the points\n",
    "    gdf_upstream_points = gpd.GeoDataFrame(geometry=list_upstream_points, crs=gdf_flowpath_with_attrib.crs)\n",
    "\n",
    "    # Add the id list to the gdf\n",
    "    gdf_upstream_points['id'] = list_id\n",
    "\n",
    "    # Create a coloumn that states if a startpoint is within the 2d area\n",
    "    gdf_upstream_points['within_2darea'] = gdf_upstream_points.geometry.within(gdf_2d_area_polygon_nextgen.iloc[0].geometry)\n",
    "    \n",
    "    # add attribute to points from the corresponding stream\n",
    "    # Specify the columns to keep\n",
    "    columns_to_keep = ['id', 'mainstem', 'tot_drainage_areasqkm', 'order']\n",
    "\n",
    "    # Drop all columns except the specified ones\n",
    "    gdf_flowpath_for_join = gdf_flowpath_with_attrib[columns_to_keep]\n",
    "\n",
    "    # Perform left join on 'id' to add the selecte attributes\n",
    "    gdf_upstream_points = gdf_upstream_points.merge(gdf_flowpath_for_join, on='id', how='left')\n",
    "    \n",
    "    return(gdf_upstream_points)\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589bfbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++\n",
    "def fn_create_cell_gdf(hdf5_file_path, str_hdf_folder_2darea):\n",
    "    \"\"\"\n",
    "    Create a GeoDataFrame of cells from HDF5 data.\n",
    "\n",
    "    Parameters:\n",
    "    hdf5_file_path (str): The file path to the HDF5 file.\n",
    "    str_hdf_folder_2darea (str): The folder containing 2D area data within the HDF5 file.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing polygons representing cells, \n",
    "                  constructed from the face point coordinates extracted from the HDF5 file.\n",
    "    \"\"\"\n",
    "    # location of Face Point Coordiantes in HDF5\n",
    "    str_facepoint_coords = str_hdf_folder_2darea + 'FacePoints Coordinate'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "        # Extract X and Y coordinates\n",
    "        x_coordinates = hdf_file[str_facepoint_coords][:, 0]\n",
    "        y_coordinates = hdf_file[str_facepoint_coords][:, 1]\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df_facepoints = pd.DataFrame({'X': x_coordinates, 'Y': y_coordinates})\n",
    "\n",
    "    # location of Indecies of facepoints making up the cells\n",
    "    str_cells_facepoint_indexes = str_hdf_folder_2darea + 'Cells FacePoint Indexes'\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "        # Extract FacePoints Coordinate data\n",
    "        facepoints_data = hdf_file[str_cells_facepoint_indexes][:]\n",
    "\n",
    "        # Extract the projection\n",
    "        projection_wkt = hdf_file.attrs['Projection'].decode('utf-8')\n",
    "\n",
    "    # Create a pandas DataFrame from the array\n",
    "    df_cells_by_facepoints = pd.DataFrame(facepoints_data)\n",
    "\n",
    "    # Create a GeoDataFrame to store the polygons\n",
    "    geometry = []\n",
    "\n",
    "    for row in facepoints_data:\n",
    "        polygon_coords = []\n",
    "\n",
    "        for idx in row:\n",
    "            if idx != -1:\n",
    "                x = df_facepoints.loc[idx, 'X']\n",
    "                y = df_facepoints.loc[idx, 'Y']\n",
    "                polygon_coords.append((x, y))\n",
    "        # Connect to the first point to close the polygon\n",
    "        polygon_coords.append(polygon_coords[0])\n",
    "        geometry.append(Polygon(polygon_coords))\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    gdf_cells = gpd.GeoDataFrame(geometry=geometry, columns=['geometry'], crs=projection_wkt)\n",
    "\n",
    "    return gdf_cells\n",
    "# +++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17586e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "def fn_determine_starting_hceras_cells(hdf_file_path,\n",
    "                                       gdf_upstream_points):\n",
    "\n",
    "    # get the HEC-RAS cell number for each upstream point\n",
    "\n",
    "    print('Extracting HEC-RAS computational cell polygons...')\n",
    "\n",
    "    # Specify the HDF5 file path and group path\n",
    "    str_hdf_2darea_root_folder = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "    # Get names of HDF5 Group objects in the specified group\n",
    "    list_group_names = fn_get_group_names(hdf_file_path, str_hdf_2darea_root_folder)\n",
    "\n",
    "    str_hdf_folder_2darea = str_hdf_2darea_root_folder + list_group_names[0] + '/'\n",
    "    gdf_cells = fn_create_cell_gdf(hdf_file_path, str_hdf_folder_2darea)\n",
    "\n",
    "    print(f' -- Number of cells in {list_group_names[0]}: {len(gdf_cells)}')\n",
    "\n",
    "    # create points that are in the same projection as the HEC-RAS Model\n",
    "    gdf_upstream_points_hecras_projection = gdf_upstream_points.to_crs(gdf_cells.crs)\n",
    "\n",
    "    print(f'Determining starting cell for {len(gdf_upstream_points_hecras_projection)} points...')\n",
    "\n",
    "    # Create a spatial index for the polygon GeoDataFrame\n",
    "    sindex = gdf_cells.sindex\n",
    "\n",
    "    # Create an empty list to store the indices of cells that each point is inside\n",
    "    cell_indices = []\n",
    "\n",
    "    # Iterate over each point in the point GeoDataFrame\n",
    "    for point in gdf_upstream_points_hecras_projection.geometry:\n",
    "        # Find the index of the cell that contains the point\n",
    "        possible_matches_index = list(sindex.intersection(point.bounds))\n",
    "        possible_matches = gdf_cells.iloc[possible_matches_index]\n",
    "        precise_matches = possible_matches[possible_matches.contains(point)]\n",
    "        if len(precise_matches) > 0:\n",
    "            # Append the index of the cell to the list\n",
    "            cell_indices.append(precise_matches.index[0])\n",
    "        else:\n",
    "            # Point is not inside any cell\n",
    "            cell_indices.append(None)\n",
    "\n",
    "    # Add the cell indices as a new column to the point GeoDataFrame\n",
    "    gdf_upstream_points['idx_start_cell'] = cell_indices\n",
    "\n",
    "    # Filter the for only points within 2darea\n",
    "    gdf_upstream_points_inside_area = gdf_upstream_points[(gdf_upstream_points['within_2darea'] == True)]\n",
    "\n",
    "    return(gdf_upstream_points_inside_area)\n",
    "# ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a841fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "def fn_find_most_downstream_node(graph, start_node):\n",
    "    visited = set()\n",
    "    stack = [start_node]\n",
    "\n",
    "    while stack:\n",
    "        current_node = stack.pop()\n",
    "        if current_node not in visited:\n",
    "            visited.add(current_node)\n",
    "            neighbors = list(graph.successors(current_node))  # Get successors (outgoing edges)\n",
    "            stack.extend(neighbors)\n",
    "\n",
    "    return max(visited)  # Return the highest node ID found\n",
    "# ----------------------\n",
    "\n",
    "# ----------------\n",
    "def fn_find_path_between_nodes(graph, start_node, end_node):\n",
    "    visited = set()\n",
    "    stack = [(start_node, [start_node])]\n",
    "\n",
    "    while stack:\n",
    "        current_node, path = stack.pop()\n",
    "        if current_node == end_node:\n",
    "            return path\n",
    "        if current_node not in visited:\n",
    "            visited.add(current_node)\n",
    "            neighbors = list(graph.successors(current_node))\n",
    "            for neighbor in neighbors:\n",
    "                stack.append((neighbor, path + [neighbor]))\n",
    "    return None\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061f1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "def fn_compute_travel_distance_per_point(gdf_flowpath_with_attrib, \n",
    "                                         gpkg_nextgen_path, \n",
    "                                         gdf_upstream_points):\n",
    "\n",
    "    print('Compute travel distance per simulation...')\n",
    "    \n",
    "    # getting a list of nexus id's from the flowpaths 'toid'\n",
    "    list_unique_nodes = gdf_flowpath_with_attrib['toid'].unique().tolist()\n",
    "\n",
    "    # read in the hydrofabric's nexus\n",
    "    gdf_nexus = gpd.read_file(gpkg_nextgen_path, layer='nexus')\n",
    "\n",
    "    # filter to just nexus in list_unique_nodes\n",
    "    gdf_nexus_on_streams = gdf_nexus[gdf_nexus['id'].isin(list_unique_nodes)]\n",
    "\n",
    "    # Combine points and lines into a single GeoDataFrame - preperation for graph creation\n",
    "    gdf_flow_network = gpd.GeoDataFrame(pd.concat([gdf_nexus_on_streams, gdf_flowpath_with_attrib], ignore_index=True),\n",
    "                                        crs=gdf_flowpath_with_attrib.crs)\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add edges to the graph based on 'id' and 'toid' fields\n",
    "    edges = gdf_flow_network[['id', 'toid']].values.tolist()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Now, let's add attributes to the nodes using the additional columns\n",
    "    for index, row in gdf_flow_network.iterrows():\n",
    "        node_id = row['id']\n",
    "        attributes = {'mainstem': row['mainstem'],\n",
    "                    'tot_drainage_areasqkm': row['tot_drainage_areasqkm']}\n",
    "        G.nodes[node_id].update(attributes)\n",
    "\n",
    "    # -- Some Graph Statistics ---\n",
    "    print('Hydrofabric Statistics:')\n",
    "    # Number of nodes\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    print(\"   Number of nodes:\", num_nodes)\n",
    "\n",
    "    # Number of edges\n",
    "    num_edges = G.number_of_edges()\n",
    "    print(\"   Number of edges:\", num_edges)\n",
    "\n",
    "    # Average degree\n",
    "    avg_degree = round(sum(dict(G.degree()).values()) / num_nodes, 2)\n",
    "    print(\"   Average degree:\", avg_degree)\n",
    "\n",
    "    # Calculate the number of weakly connected components\n",
    "    num_components = nx.number_weakly_connected_components(G)\n",
    "    print(\"   Number of weakly connected components:\", num_components)\n",
    "    # -- End Some Graph Statistics ---\n",
    "    \n",
    "    # -- Determine travel distance for each node in gdf_upstream_points\n",
    "    list_travel_dist_flt = []\n",
    "    list_avg_slope = []\n",
    "\n",
    "    for index, row in gdf_upstream_points.iterrows():\n",
    "\n",
    "        str_start_node = row['id']\n",
    "        str_downstream_node = fn_find_most_downstream_node(G, str_start_node)\n",
    "\n",
    "        # Create a list of nodes (flowpath and nexus) down the travel path\n",
    "        list_travel_path = fn_find_path_between_nodes(G, str_start_node, str_downstream_node)\n",
    "\n",
    "        # get just the flowpaths from gdf_flowpath_with_attrib in list_travel_path\n",
    "        gdf_streams_travel_path = gdf_flowpath_with_attrib[gdf_flowpath_with_attrib['id'].isin(list_travel_path)]\n",
    "\n",
    "        # vertical fall per flowpath\n",
    "        gdf_streams_travel_path = gdf_streams_travel_path.copy()\n",
    "        gdf_streams_travel_path['delta_z'] = gdf_streams_travel_path['lengthkm'] * gdf_streams_travel_path['So']\n",
    "\n",
    "        # Sum the values in the 'delta_z' column and rounded \n",
    "        flt_total_delta_z = round(gdf_streams_travel_path['delta_z'].sum(), 5)\n",
    "\n",
    "        # Sum the values in the 'lengthkm' column and round to three decimal places\n",
    "        flt_total_length_km = round(gdf_streams_travel_path['lengthkm'].sum(), 3)\n",
    "\n",
    "        # Sum the values in the 'lengthkm' column and round to three decimal places\n",
    "        flt_avg_slope = flt_total_delta_z / flt_total_length_km\n",
    "\n",
    "        list_travel_dist_flt.append(flt_total_length_km)\n",
    "        list_avg_slope.append(flt_avg_slope)\n",
    "\n",
    "    gdf_upstream_points['flow_dist_km'] = list_travel_dist_flt\n",
    "    gdf_upstream_points['slope_average'] = list_avg_slope\n",
    "    \n",
    "    return(gdf_upstream_points)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "558a2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Nextgen Hydrofabric ~5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_24944\\1282804222.py:17: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for geom in geom_items:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting HEC-RAS computational cell polygons...\n",
      " -- Number of cells in 1207020501: 220317\n",
      "Determining starting cell for 72 points...\n",
      "Compute travel distance per simulation...\n",
      "Hydrofabric Statistics:\n",
      "   Number of nodes: 110\n",
      "   Number of edges: 107\n",
      "   Average degree: 1.95\n",
      "   Number of weakly connected components: 3\n",
      "CPU times: total: 43.1 s\n",
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gdf_2d_area_polygon = get_gdf_of_2d_area(hdf_file_path)\n",
    "gdf_flowpath_with_attrib = fn_extract_flowpaths_gdf(gdf_2d_area_polygon, gpkg_nextgen_path)\n",
    "gdf_2d_area_polygon_nextgen = gdf_2d_area_polygon.to_crs(gdf_flowpath_with_attrib.crs)\n",
    "gdf_upstream_points = fn_create_upstream_flowpath_points(gdf_flowpath_with_attrib, gdf_2d_area_polygon_nextgen)\n",
    "\n",
    "gdf_upstream_points = fn_determine_starting_hceras_cells(hdf_file_path,gdf_upstream_points)\n",
    "gdf_upstream_points = fn_compute_travel_distance_per_point(gdf_flowpath_with_attrib, gpkg_nextgen_path, gdf_upstream_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47059748",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_2d_area_polygon_nextgen = gdf_2d_area_polygon.to_crs(gdf_flowpath_with_attrib.crs)\n",
    "\n",
    "# Write GeoDataFrames to GeoPackage as separate layers\n",
    "gdf_upstream_points.to_file(output_path, layer='02_flow_points', driver=\"GPKG\")\n",
    "gdf_flowpath_with_attrib.to_file(output_path, layer='01_stream_lines', driver=\"GPKG\")\n",
    "gdf_2d_area_polygon_nextgen.to_file(output_path, layer='00_area_2d', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28553d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - rl_gages could have multiple gages on that reach -- is this a problem?\n",
    "\n",
    "# TODO - If stream crosses through 2darea polygon, but doesn't cross the boundary condition, then\n",
    "# water can't flow out.  This stream and the upstream point should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40fd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travel time is a function of flow and average slope\n",
    "\n",
    "import math\n",
    "# determine the travel time down reach\n",
    "\n",
    "# ------------\n",
    "def fn_calculate_hydra_radius(flt_Q_cfs):\n",
    "    # from a Rh vs flow derivaton from a HEC-RAS 1D model of Wolf Creek near Fredricksburg, TX\n",
    "    # This is a stream order of ~1 ... A higher stream order is likely to have a higher hydraulic radius\n",
    "    # so hopefully this is a convervative estiamte\n",
    "    flt_hydra_radius = 1.036 * math.log(flt_Q_cfs) - 2.9876\n",
    "    return flt_hydra_radius\n",
    "# ------------\n",
    "\n",
    "# ------------\n",
    "def fn_estimate_travel_time(flt_mannings_n, flt_length_km, flt_slope, flt_Q_cfs):\n",
    "    flt_Rh = round(fn_calculate_hydra_radius(flt_Q_cfs),2)\n",
    "    \n",
    "    # Set minimum allowed hydraulic radius\n",
    "    flt_min_Rh = 0.2\n",
    "\n",
    "    # with regression, Rh could be negative\n",
    "    if flt_Rh < flt_min_Rh:\n",
    "        flt_Rh = flt_min_Rh\n",
    "        \n",
    "    flt_length_m = flt_length_km * 1000\n",
    "\n",
    "    flt_length_km = flt_length_km * 1000\n",
    "    flt_Rh_2_3 = flt_Rh ** 0.66667 # hydraulic radius^(2/3)\n",
    "    flt_slope_1_2 = flt_slope ** 0.50 # square root of the slope\n",
    "\n",
    "    flt_time_hr = round(((flt_length_m * flt_mannings_n)/(flt_Rh_2_3 * flt_slope_1_2))/3600,0)\n",
    "    \n",
    "    return(flt_time_hr)\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ceca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_mannings_n = 0.07\n",
    "flt_length_km = 66.91\n",
    "flt_slope = 0.005 #this is in m/m\n",
    "flt_Q_cfs = 1 # this is in cfs\n",
    "\n",
    "flt_time_hr = fn_estimate_travel_time(flt_mannings_n, flt_length_km, flt_slope, flt_Q_cfs)\n",
    "\n",
    "flt_time_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5823587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.783356312683663"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_calculate_hydra_radius(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecd801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
