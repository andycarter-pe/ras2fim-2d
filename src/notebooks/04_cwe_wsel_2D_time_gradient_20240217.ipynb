{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636a8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Revised - 2024.04.19\n",
    "# Determine all the cells that are wet within a 2D HEC-RAS model\n",
    "\n",
    "import h5py\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37cb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incoming from previous steps\n",
    "\n",
    "# ----------------------\n",
    "# Path to the HDF file\n",
    "hdf_file_path = r'E:\\HECRAS_2D_12070205\\base_model_20240414_copy\\BLE_LBSG_501.p04.hdf'\n",
    "\n",
    "# ************\n",
    "flt_firehose_flow = 14100\n",
    "str_start_node = \"wb-2410249\"\n",
    "flt_mainstem = 1884413.0\n",
    "str_run_name = '1884413_wb-2410249_29-hr_14100-cfs'\n",
    "\n",
    "dict_hec_info = {'HEC-RAS_Version': 'HEC-RAS 6.5 February 2024',\n",
    " 'Project_Path': 'E:\\\\HECRAS_2D_12070205\\\\base_model_20240414_copy\\\\BLE_LBSG_501.prj',\n",
    " 'Project_Title': 'LBSG_501',\n",
    " 'Plan_Path': 'E:\\\\HECRAS_2D_12070205\\\\base_model_20240414_copy\\\\BLE_LBSG_501.p04',\n",
    " 'Geometry_Path': 'E:\\\\HECRAS_2D_12070205\\\\base_model_20240414_copy\\\\BLE_LBSG_501.g04',\n",
    " 'Geometry_HDF_Path': 'E:\\\\HECRAS_2D_12070205\\\\base_model_20240414_copy\\\\BLE_LBSG_501.g04.hdf',\n",
    " 'Unsteady_File_Path': 'E:\\\\HECRAS_2D_12070205\\\\base_model_20240414_copy\\\\BLE_LBSG_501.u04',\n",
    " '2D_Flow_Area_Names': ['1207020501']}\n",
    "# ************\n",
    "\n",
    "# Output\n",
    "# Specify the path where you want to save the GeoPackage file\n",
    "output_path = r'E:\\sample_2d_output\\hydraulic_results_1884413_wb-2410249_29-hr_14100-cfs.gpkg'\n",
    "\n",
    "# ++++++++++++++++\n",
    "# run parameters\n",
    "#\n",
    "# input - nextgen hydropackage geopackage\n",
    "gpkg_path = r'E:\\ras2fim-2d\\nextgen-test\\nextgen_12.gpkg'\n",
    "\n",
    "# number of iterations to buffer the nearest cells. 0 is just the nearest cells.\n",
    "# 1 = the nearest cells plus the first cells touching those nearert... growing from there.\n",
    "int_buffer_cells = 5\n",
    "\n",
    "# Stable is a rolling average gradient of WSEL that is less than flt_max_allowed_gradient\n",
    "flt_max_allowed_gradient = 0.009\n",
    "\n",
    "int_len_gradient = 4 #number of time steps to get average gradient\n",
    "# ++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da10a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "def fn_compute_average_gradients(values, int_len_gradient):\n",
    "    num_values = len(values)\n",
    "    list_avg_gradient = []\n",
    "\n",
    "    for i in range(num_values):\n",
    "        if i < int_len_gradient:\n",
    "            avg_gradient = np.nan\n",
    "        else:\n",
    "            gradient = (values[i] - values[i - int_len_gradient]) / int_len_gradient\n",
    "            avg_gradient = gradient / int_len_gradient\n",
    "            \n",
    "        list_avg_gradient.append(avg_gradient)\n",
    "\n",
    "    return list_avg_gradient\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93fac486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "def fn_get_group_names(hdf5_file_path, group_path):\n",
    "    \"\"\"\n",
    "    Retrieve the names of groups within a specified HDF5 file under a given group path.\n",
    "\n",
    "    Parameters:\n",
    "    hdf5_file_path (str): The file path to the HDF5 file.\n",
    "    group_path (str): The path to the group whose subgroups' names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    list or None: A list containing the names of groups found under the specified group path. \n",
    "                  Returns None if the group path does not exist in the HDF5 file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "            # Check if the specified group path exists\n",
    "            if group_path in hdf_file:\n",
    "                group = hdf_file[group_path]\n",
    "\n",
    "                # Extract names of HDF5 Group objects\n",
    "                group_names = [name for name in group if isinstance(group[name], h5py.Group)]\n",
    "\n",
    "                return group_names\n",
    "            else:\n",
    "                print(f\"Group '{group_path}' not found in the HDF5 file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c73d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1207020501']\n"
     ]
    }
   ],
   "source": [
    "# Specify the HDF5 file path and group path\n",
    "group_path = '/Geometry/2D Flow Areas/'\n",
    "\n",
    "# Get names of HDF5 Group objects in the specified group\n",
    "list_group_names = fn_get_group_names(hdf_file_path, group_path)\n",
    "print(list_group_names)\n",
    "\n",
    "# determine all the cells that are 'wet'\n",
    "\n",
    "str_hdf_folder_results = '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/'\n",
    "str_hdf_folder_results = str_hdf_folder_results + list_group_names[0] + '/'\n",
    "\n",
    "str_cell_min_elev_path = group_path + list_group_names[0] + '/' + 'Cells Minimum Elevation'\n",
    "\n",
    "# Open the HDF file\n",
    "with h5py.File(hdf_file_path, 'r') as hdf_file:\n",
    "    wsel_dataset_path = str_hdf_folder_results + 'Water Surface'\n",
    "    wsel_data_per_cell = hdf_file[wsel_dataset_path][:]\n",
    "    \n",
    "    arr_min_elev_per_cell = hdf_file[str_cell_min_elev_path][:]\n",
    "    \n",
    "# Transpose the array\n",
    "arr_wsel_data_per_cell_t = wsel_data_per_cell.T\n",
    "\n",
    "# Identify nan values and replace them with zeros\n",
    "#arr_min_elev_per_cell[np.isnan(arr_min_elev_per_cell)] = 0\n",
    "\n",
    "# Subtract arr_min_elev_per_cell from each row of arr_wsel_data_per_cell_t\n",
    "arr_depth_per_cell = arr_wsel_data_per_cell_t - arr_min_elev_per_cell[:, np.newaxis]\n",
    "\n",
    "# Identify nan values and replace them with zeros\n",
    "arr_depth_per_cell[np.isnan(arr_depth_per_cell)] = 0\n",
    "\n",
    "list_indices_per_column = []\n",
    "\n",
    "# Iterate over each column index\n",
    "for column_index in range(arr_depth_per_cell.shape[1]):\n",
    "    # Get values in the current column\n",
    "    column_values = arr_depth_per_cell[:, column_index]\n",
    "    \n",
    "    # Find indices where values are greater than 0\n",
    "    indices = np.where(column_values > 0)[0]\n",
    "    \n",
    "    list_indices_per_column.append(indices)\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_indices = [index for sublist in list_indices_per_column for index in sublist]\n",
    "\n",
    "# Get unique indices\n",
    "unique_indices = np.unique(flattened_indices)\n",
    "list_unique_indices_sorted = np.sort(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f373e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the array to those cells that are wet\n",
    "arr_depth_wet_cells = arr_depth_per_cell[list_unique_indices_sorted]\n",
    "\n",
    "# Round all values to two decimal points\n",
    "arr_depth_wet_cells = np.round(arr_depth_wet_cells, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617dcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the results\n",
    "list_results = []\n",
    "\n",
    "for row in arr_depth_wet_cells:\n",
    "    list_result = fn_compute_average_gradients(row, int_len_gradient)\n",
    "    \n",
    "    # Append the result to the list of results\n",
    "    list_results.append(list_result)\n",
    "    \n",
    "# Convert the list of lists into a numpy array\n",
    "arr_list_wsel_gradient = np.array(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e597cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shapefile of all the cells in unique_indices\n",
    "\n",
    "str_hdf_folder_2darea = group_path + list_group_names[0] + '/'\n",
    "hdf5_file_path = hdf_file_path\n",
    "\n",
    "# Location of Face Point Coordinates in HDF5\n",
    "str_facepoint_coords = str_hdf_folder_2darea + 'FacePoints Coordinate'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "    # Extract X and Y coordinates\n",
    "    x_coordinates = hdf_file[str_facepoint_coords][:, 0]\n",
    "    y_coordinates = hdf_file[str_facepoint_coords][:, 1]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_facepoints = pd.DataFrame({'X': x_coordinates, 'Y': y_coordinates})\n",
    "\n",
    "# Location of Indices of face points making up the cells\n",
    "str_cells_facepoint_indexes = str_hdf_folder_2darea + 'Cells FacePoint Indexes'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_path, 'r') as hdf_file:\n",
    "    # Extract face points coordinate data\n",
    "    facepoints_data = hdf_file[str_cells_facepoint_indexes][:]\n",
    "\n",
    "    # Extract the projection\n",
    "    projection_wkt = hdf_file.attrs['Projection'].decode('utf-8')\n",
    "\n",
    "# Create a GeoDataFrame to store the polygons\n",
    "geometry = []\n",
    "indices = []\n",
    "\n",
    "for row_idx, row in enumerate(facepoints_data):\n",
    "    polygon_coords = []\n",
    "    \n",
    "    if row_idx in list_unique_indices_sorted:\n",
    "        for idx in row:\n",
    "            if idx != -1:\n",
    "                x = df_facepoints.loc[idx, 'X']\n",
    "                y = df_facepoints.loc[idx, 'Y']\n",
    "                polygon_coords.append((x, y))\n",
    "        # Check if the polygon has at least 3 points (needed to create a polygon)\n",
    "        if len(polygon_coords) >= 3:\n",
    "            # Connect to the first point to close the polygon\n",
    "            polygon_coords.append(polygon_coords[0])\n",
    "            geometry.append(Polygon(polygon_coords))\n",
    "            indices.append(row_idx)  # Append the row index as the cell index\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf_cells = gpd.GeoDataFrame(geometry=geometry, index=indices, columns=['geometry'], crs=projection_wkt)\n",
    "\n",
    "# create a new coloumn that contains the cell index\n",
    "gdf_cells['cell_idx'] = gdf_cells.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9408e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_depth_wet_cells_nan = arr_depth_wet_cells\n",
    "\n",
    "for row_idx in range(arr_depth_wet_cells_nan.shape[0]):\n",
    "    row = arr_depth_wet_cells_nan[row_idx]\n",
    "    \n",
    "    # Find the index of the first non-zero element in the row\n",
    "    first_non_zero_index = np.argmax(row != 0)\n",
    "    \n",
    "    # Set all elements before the first non-zero element to NaN\n",
    "    row[:first_non_zero_index] = np.nan\n",
    "\n",
    "# Finding locations where values are nan in arr_depth_wet_cells_nan\n",
    "arr_nan_indices = np.isnan(arr_depth_wet_cells_nan)\n",
    "\n",
    "# Setting values to nan in arr_list_wsel_gradient at corresponding locations\n",
    "arr_list_wsel_gradient[arr_nan_indices] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_wsel_gradient_stability = arr_list_wsel_gradient.copy()\n",
    "\n",
    "# Using list comprehension to get absolute values of floats while ignoring nan\n",
    "arr_wsel_gradient_stability = np.abs(arr_wsel_gradient_stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0bd7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [f'wsel_grad_t{i+1:03d}' for i in range(len(arr_wsel_gradient_stability[0]))]\n",
    "\n",
    "# Convert arr_list_wsel_gradient to a DataFrame with the specified column names\n",
    "df_wsel_grad = pd.DataFrame(arr_wsel_gradient_stability, columns=column_names)\n",
    "\n",
    "# Add list_unique_indices_sorted as a new column named 'unique_indices_sorted'\n",
    "df_wsel_grad['cell_idx'] = list_unique_indices_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2846530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_wsel_gradient = pd.merge(gdf_cells, df_wsel_grad, on='cell_idx', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2ab940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming gdf_wsel_gradient is your GeoDataFrame\n",
    "#output_path = r'E:\\working\\export_wsel_gradient_values_ar.gpkg'\n",
    "\n",
    "# Export GeoDataFrame to a GeoPackage\n",
    "#gdf_wsel_gradient.to_file(output_path, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41b394b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions of the first value where not NaN and less than 0.009 for each row:\n",
      "[12  8  5 ... 18 18 18]\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Added 2024.04.14\n",
    "# Determine the index of the first stable cell calcaulation\n",
    "\n",
    "# Initialize an empty list to store the positions\n",
    "arr_positions = []\n",
    "\n",
    "# Iterate over each row\n",
    "for row in arr_wsel_gradient_stability:\n",
    "    # Find the first non-NaN value that is less than 0.009\n",
    "    \n",
    "    index = np.where(~np.isnan(row) & (row < flt_max_allowed_gradient))[0]\n",
    "    if index.size > 0:\n",
    "        arr_positions.append(index[0])\n",
    "    else:\n",
    "        arr_positions.append(None)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "arr_positions = np.array(arr_positions)\n",
    "\n",
    "# Replace 'None' with -1\n",
    "arr_positions = np.where(arr_positions == None, -1, arr_positions)\n",
    "\n",
    "# Convert positions to integers\n",
    "arr_positions_int = arr_positions.astype(int)\n",
    "\n",
    "print(\"Positions of the first value where not NaN and less than 0.009 for each row:\")\n",
    "print(arr_positions_int)\n",
    "\n",
    "# Creating DataFrame\n",
    "df_hours_to_stability = pd.DataFrame({'cell_idx': list_unique_indices_sorted, 'hours_to_stable': arr_positions_int})\n",
    "\n",
    "# Create a gdf of cells with \"hours_to_stability\"\n",
    "# Note that an unstable cells is -1\n",
    "gdf_hours_to_stable = pd.merge(gdf_cells, df_hours_to_stability, on='cell_idx', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d72ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from NextGen hydrofabric - get all the streamms where the 'mainstem == flt_mainstem' Example: 1884894.0\n",
    "\n",
    "# Load the GeoPackage layers\n",
    "gdf_flowpaths = gpd.read_file(gpkg_path, layer='flowpaths')\n",
    "gdf_nexus = gpd.read_file(gpkg_path, layer='nexus')\n",
    "\n",
    "# find all the reaches that have a 'mainstem' == flt_mainstem\n",
    "gdf_selected_mainstem_streams = gdf_flowpaths[gdf_flowpaths['mainstem'] == flt_mainstem]\n",
    "\n",
    "# Set the crs of the mainstem to crs of cells\n",
    "gdf_selected_mainstem_streams = gdf_selected_mainstem_streams.to_crs(gdf_cells.crs)\n",
    "\n",
    "# Compute the centroid for every cell's polygon\n",
    "gdf_cells['geom_centroid'] = gdf_cells.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c1eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "def fn_find_nearest_flowpath_and_distance(centroid, gdf_mainstems):\n",
    "    # Calculate the distances from the centroid to all mainstem lines\n",
    "    distances = gdf_mainstems.distance(centroid)\n",
    "    # Find the index of the minimum distance\n",
    "    int_nearest_index = distances.idxmin()\n",
    "    flt_nearest_distance = distances.min()\n",
    "    \n",
    "    str_nearest_id = gdf_mainstems.loc[int_nearest_index]['id']\n",
    "    \n",
    "    return str_nearest_id, flt_nearest_distance\n",
    "# ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b291ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most downstream mainstem\n",
    "gdf_largest_drainage_area = gdf_selected_mainstem_streams.loc[gdf_selected_mainstem_streams['tot_drainage_areasqkm'].idxmax()]\n",
    "str_toid_with_largest_drainage_area = gdf_largest_drainage_area['toid']\n",
    "str_toid_with_largest_drainage_area\n",
    "\n",
    "gdf_selected_rows = gdf_nexus[gdf_nexus['id'] == str_toid_with_largest_drainage_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9411b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gdf_selected_rows) == 1:\n",
    "    # only one downstream node found\n",
    "    str_dwn_stream_id = gdf_selected_rows.iloc[0]['toid']\n",
    "    \n",
    "    # Find the stream in gdf_flowpaths where 'id' == str_dwn_stream_id\n",
    "    \n",
    "    # Finding the stream\n",
    "    gdf_downstream_stream = gdf_flowpaths[gdf_flowpaths['id'] == str_dwn_stream_id]\n",
    "    \n",
    "    # Set the crs of the mainstem to crs of cells\n",
    "    gdf_downstream_stream = gdf_downstream_stream.to_crs(gdf_cells.crs)\n",
    "    \n",
    "    # Concatenating DataFrames\n",
    "    gdf_all_streams = pd.concat([gdf_downstream_stream, gdf_selected_mainstem_streams])\n",
    "else:\n",
    "    gdf_all_streams = gdf_selected_mainstem_streams\n",
    "    \n",
    "    \n",
    "# Apply the function to each centroid in gdf_cells\n",
    "nearest_info = gdf_cells['geom_centroid'].apply(lambda x: fn_find_nearest_flowpath_and_distance(x, gdf_all_streams))\n",
    "\n",
    "gdf_cells['nearest_flowpath'] = nearest_info.apply(lambda x: x[0])\n",
    "gdf_cells['distance_to_nearest_flowpath'] = nearest_info.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e7575b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique streams in gdf_all_streams\n",
    "list_unique_stream_ids = gdf_all_streams['id'].unique().tolist()\n",
    "\n",
    "# remove the downstream stream\n",
    "# we don't want this polygons as it is on another river\n",
    "list_unique_stream_ids.remove(str_dwn_stream_id)\n",
    "\n",
    "# For each item in list_unique_stream_ids, create polygons of the disolved cells in gdf_cells.  Disolve on 'nearest_flowpath'\n",
    "\n",
    "list_dissolved_polygons_gdf = []\n",
    "\n",
    "for stream_id in list_unique_stream_ids:\n",
    "    # Filter cells associated with the current stream ID\n",
    "    cells_for_stream = gdf_cells[gdf_cells['nearest_flowpath'] == stream_id]\n",
    "    \n",
    "    # Dissolve cells based on the 'nearest_flowpath' column\n",
    "    dissolved = cells_for_stream.dissolve(by='nearest_flowpath')\n",
    "    \n",
    "    # Drop specified columns\n",
    "    dissolved.drop(columns=['cell_idx', 'distance_to_nearest_flowpath'], inplace=True)\n",
    "\n",
    "    # Append the dissolved polygon to the list\n",
    "    list_dissolved_polygons_gdf.append(dissolved)\n",
    "\n",
    "\n",
    "# There can be streams along the mainsteam that have no geometry.  This is because the \n",
    "# 'firehose' is downstream of these reach or the water never got to that reach.\n",
    "# Drop those reaches without geometry from list_dissolved_polygons_gdf\n",
    "\n",
    "# Remove reaches without geometry from list_dissolved_polygons_gdf\n",
    "list_dissolved_polygons_gdf_filtered = []\n",
    "\n",
    "for gdf_merged_poly in list_dissolved_polygons_gdf:\n",
    "    if not gdf_merged_poly.empty:\n",
    "        list_dissolved_polygons_gdf_filtered.append(gdf_merged_poly)\n",
    "        \n",
    "list_dissolved_polygons_gdf = list_dissolved_polygons_gdf_filtered\n",
    "\n",
    "list_buffered_shp_polys = []\n",
    "list_mainstem = []\n",
    "\n",
    "for gdf_merged_poly in list_dissolved_polygons_gdf:\n",
    "    \n",
    "    str_mainstem = gdf_merged_poly.index[0]\n",
    "    list_mainstem.append(str_mainstem)\n",
    "    \n",
    "    shp_polygon_to_check = gdf_merged_poly['geometry'].iloc[0]\n",
    "\n",
    "    for i in range(int_buffer_cells):\n",
    "        gdf_intersecting_cells = gdf_cells[gdf_cells.geometry.touches(shp_polygon_to_check)]\n",
    "        merged_geometry = unary_union(gdf_intersecting_cells.geometry)\n",
    "        merged_polygon = shp_polygon_to_check.union(merged_geometry)\n",
    "        shp_polygon_to_check = merged_polygon\n",
    "\n",
    "    list_buffered_shp_polys.append(shp_polygon_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame from the list of shapely objects and list of strings\n",
    "gdf_buffered_limits = gpd.GeoDataFrame({'flowpath': list_mainstem, 'geometry': list_buffered_shp_polys})\n",
    "\n",
    "# Set the crs of the newly created geodataframe\n",
    "gdf_buffered_limits.crs =  gdf_cells.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f52d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gdf_buffered_limits into a single polygon\n",
    "\n",
    "# Assuming your GeoDataFrame is named gdf and contains a column 'geometry' with multiple polygons\n",
    "\n",
    "# First, ensure that the 'geometry' column contains Polygon or MultiPolygon objects\n",
    "# This is usually done when reading the GeoDataFrame, but just in case\n",
    "gdf_buffered_limits['geometry'] = gdf_buffered_limits['geometry'].apply(lambda geom: geom if isinstance(geom, MultiPolygon) else MultiPolygon([geom]))\n",
    "\n",
    "# Then, merge all the polygons into a single MultiPolygon\n",
    "merged_geometry = gdf_buffered_limits['geometry'].unary_union\n",
    "\n",
    "# Create a new GeoDataFrame with the merged geometry\n",
    "gdf_merged_flooeded_cells = gpd.GeoDataFrame(geometry=[merged_geometry])\n",
    "\n",
    "# Set the crs of the newly created geodataframe\n",
    "gdf_merged_flooeded_cells.crs =  gdf_buffered_limits.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475af03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\civil\\anaconda3\\envs\\tx-bridge\\lib\\site-packages\\geopandas\\tools\\clip.py:67: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  clipped.loc[\n"
     ]
    }
   ],
   "source": [
    "# Clip gdf_cells using gdf_merged_flooded_cells geometry\n",
    "gdf_cells_clipped = gpd.clip(gdf_cells, gdf_merged_flooeded_cells.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38561f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns from gdf_hours_to_stable excluding 'geometry'\n",
    "gdf_hours_to_stable_subset = gdf_hours_to_stable.drop(columns=['geometry'])\n",
    "\n",
    "# Drop coloumns from gdf_cells_clipped\n",
    "gdf_cells_clipped_subset = gdf_cells_clipped.drop(columns=['geom_centroid', 'distance_to_nearest_flowpath'])\n",
    "\n",
    "# Perform left join\n",
    "gdf_cells_clipped_w_hour = pd.merge(gdf_cells_clipped_subset, gdf_hours_to_stable_subset, on='cell_idx', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e632f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the array of WSEL, get the stable timestep's water surface elevation for each cell\n",
    "list_wsel_per_cell = []\n",
    "\n",
    "for index,row in gdf_cells_clipped_w_hour.iterrows():\n",
    "    x = row['cell_idx']\n",
    "    y = row['hours_to_stable']\n",
    "    # Note - if not stable, value is set as last time step... y=-1\n",
    "    \n",
    "    list_wsel_per_cell.append(arr_wsel_data_per_cell_t[x][y])\n",
    "    \n",
    "gdf_cells_wsel = gdf_cells_clipped_w_hour.copy()\n",
    "\n",
    "gdf_cells_wsel['wsel'] = list_wsel_per_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78a36260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a geodataframe of the gdf_cells_wsel and gdf_buffered_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1f5f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document the constant flow used in this simulation\n",
    "gdf_cells_wsel['flow_cfs'] = flt_firehose_flow\n",
    "\n",
    "gdf_cells_wsel['run_name'] = str_run_name\n",
    "\n",
    "# Correct the hours to stable... this is a moving average, so subtract this moving average to get to\n",
    "# correct travel time for the given flow.\n",
    "\n",
    "# Subtract int_len_gradient from 'hours_to_stable' column in every row\n",
    "gdf_cells_wsel['hours_to_stable'] = gdf_cells_wsel['hours_to_stable'] - int_len_gradient\n",
    "\n",
    "# Replace values in 'hours_to_stable' column <= 0 with -1\n",
    "# to preserve the 'unstable' value\n",
    "gdf_cells_wsel.loc[gdf_cells_wsel['hours_to_stable'] <= 0, 'hours_to_stable'] = -1\n",
    "\n",
    "# if gdf_cells_wsel contains any geomety that is not Polygon, drop those rows\n",
    "gdf_cells_wsel = gdf_cells_wsel[gdf_cells_wsel.geometry.geom_type == 'Polygon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae661deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many cells was this boundary buffered out\n",
    "gdf_buffered_limits['buffer_cell_count'] = int_buffer_cells\n",
    "\n",
    "# Document the constant flow used in this simulation\n",
    "gdf_buffered_limits['flow_cfs'] = flt_firehose_flow\n",
    "\n",
    "gdf_buffered_limits['run_name'] = str_run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6e4b926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flowpath</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffer_cell_count</th>\n",
       "      <th>flow_cfs</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wb-2410251</td>\n",
       "      <td>MULTIPOLYGON (((2992649.306 10278157.295, 2992...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wb-2410255</td>\n",
       "      <td>MULTIPOLYGON (((3027376.471 10269306.529, 3027...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wb-2410258</td>\n",
       "      <td>MULTIPOLYGON (((3052642.639 10239632.368, 3052...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wb-2410259</td>\n",
       "      <td>MULTIPOLYGON (((3055911.199 10237312.998, 3055...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wb-2410260</td>\n",
       "      <td>MULTIPOLYGON (((3065036.132 10228181.509, 3064...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wb-2410261</td>\n",
       "      <td>MULTIPOLYGON (((3079876.910 10224539.263, 3079...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wb-2410249</td>\n",
       "      <td>MULTIPOLYGON (((2954641.059 10296841.940, 2954...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wb-2410250</td>\n",
       "      <td>MULTIPOLYGON (((2978767.625 10288850.487, 2978...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wb-2410252</td>\n",
       "      <td>MULTIPOLYGON (((3001776.471 10275506.529, 3001...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wb-2410253</td>\n",
       "      <td>MULTIPOLYGON (((3007176.471 10273906.529, 3006...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wb-2410254</td>\n",
       "      <td>MULTIPOLYGON (((3020861.254 10269748.744, 3020...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wb-2410256</td>\n",
       "      <td>MULTIPOLYGON (((3039024.147 10266386.464, 3038...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wb-2410257</td>\n",
       "      <td>MULTIPOLYGON (((3050206.936 10252017.689, 3050...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wb-2410262</td>\n",
       "      <td>MULTIPOLYGON (((3087213.356 10224104.042, 3087...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wb-2410263</td>\n",
       "      <td>MULTIPOLYGON (((3094394.796 10220648.777, 3094...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wb-2410264</td>\n",
       "      <td>MULTIPOLYGON (((3114583.903 10215935.406, 3114...</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flowpath                                           geometry  \\\n",
       "0   wb-2410251  MULTIPOLYGON (((2992649.306 10278157.295, 2992...   \n",
       "1   wb-2410255  MULTIPOLYGON (((3027376.471 10269306.529, 3027...   \n",
       "2   wb-2410258  MULTIPOLYGON (((3052642.639 10239632.368, 3052...   \n",
       "3   wb-2410259  MULTIPOLYGON (((3055911.199 10237312.998, 3055...   \n",
       "4   wb-2410260  MULTIPOLYGON (((3065036.132 10228181.509, 3064...   \n",
       "5   wb-2410261  MULTIPOLYGON (((3079876.910 10224539.263, 3079...   \n",
       "6   wb-2410249  MULTIPOLYGON (((2954641.059 10296841.940, 2954...   \n",
       "7   wb-2410250  MULTIPOLYGON (((2978767.625 10288850.487, 2978...   \n",
       "8   wb-2410252  MULTIPOLYGON (((3001776.471 10275506.529, 3001...   \n",
       "9   wb-2410253  MULTIPOLYGON (((3007176.471 10273906.529, 3006...   \n",
       "10  wb-2410254  MULTIPOLYGON (((3020861.254 10269748.744, 3020...   \n",
       "11  wb-2410256  MULTIPOLYGON (((3039024.147 10266386.464, 3038...   \n",
       "12  wb-2410257  MULTIPOLYGON (((3050206.936 10252017.689, 3050...   \n",
       "13  wb-2410262  MULTIPOLYGON (((3087213.356 10224104.042, 3087...   \n",
       "14  wb-2410263  MULTIPOLYGON (((3094394.796 10220648.777, 3094...   \n",
       "15  wb-2410264  MULTIPOLYGON (((3114583.903 10215935.406, 3114...   \n",
       "\n",
       "    buffer_cell_count  flow_cfs                            run_name  \n",
       "0                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "1                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "2                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "3                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "4                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "5                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "6                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "7                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "8                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "9                   5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "10                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "11                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "12                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "13                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "14                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  \n",
       "15                  5     14100  1884413_wb-2410249_29-hr_14100-cfs  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_buffered_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d454f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n",
      "C:\\Users\\civil\\AppData\\Local\\Temp\\ipykernel_9644\\2819663173.py:11: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for polygon in row['geometry']:\n"
     ]
    }
   ],
   "source": [
    "# convert the gdf_buffered_limits of multipolygons to polygons, if necessary.  New row for each polygon\n",
    "\n",
    "# Create an empty list to store the new rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over each row in the GeoDataFrame\n",
    "for index, row in gdf_buffered_limits.iterrows():\n",
    "    # Check if the geometry is a MultiPolygon\n",
    "    if row['geometry'].geom_type == 'MultiPolygon':\n",
    "        # If it is, iterate over each polygon in the MultiPolygon\n",
    "        for polygon in row['geometry']:\n",
    "            # Create a new row with the same attributes but with a single Polygon geometry\n",
    "            new_row = row.drop('geometry').copy()\n",
    "            new_row['geometry'] = polygon\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        # If it's already a Polygon, just append the original row\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create a new GeoDataFrame from the list of new rows\n",
    "gdf_buffered_polygon = gpd.GeoDataFrame(new_rows, crs=gdf_buffered_limits.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e72c266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flowpath</th>\n",
       "      <th>buffer_cell_count</th>\n",
       "      <th>flow_cfs</th>\n",
       "      <th>run_name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wb-2410251</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((2992649.306 10278157.295, 2992576.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wb-2410251</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((2989882.070 10278412.128, 2989880.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wb-2410255</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3027376.471 10269306.529, 3027176.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wb-2410258</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3052642.639 10239632.368, 3052470.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wb-2410259</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3055911.199 10237312.998, 3055790.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wb-2410260</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3065036.132 10228181.509, 3064839.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wb-2410261</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3079876.910 10224539.263, 3079734.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wb-2410249</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((2954641.059 10296841.940, 2954644.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wb-2410250</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((2978767.625 10288850.487, 2978608.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wb-2410252</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3001776.471 10275506.529, 3001725.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wb-2410253</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3007176.471 10273906.529, 3006976.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wb-2410254</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3020861.254 10269748.744, 3020776.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wb-2410256</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3039024.147 10266386.464, 3038815.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wb-2410257</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3050206.936 10252017.689, 3050207.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wb-2410262</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3087213.356 10224104.042, 3087129.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wb-2410263</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3094394.796 10220648.777, 3094312.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wb-2410264</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3114583.903 10215935.406, 3114683.90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wb-2410264</td>\n",
       "      <td>5</td>\n",
       "      <td>14100</td>\n",
       "      <td>1884413_wb-2410249_29-hr_14100-cfs</td>\n",
       "      <td>POLYGON ((3113783.903 10216735.406, 3113883.90...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flowpath  buffer_cell_count  flow_cfs  \\\n",
       "0   wb-2410251                  5     14100   \n",
       "0   wb-2410251                  5     14100   \n",
       "1   wb-2410255                  5     14100   \n",
       "2   wb-2410258                  5     14100   \n",
       "3   wb-2410259                  5     14100   \n",
       "4   wb-2410260                  5     14100   \n",
       "5   wb-2410261                  5     14100   \n",
       "6   wb-2410249                  5     14100   \n",
       "7   wb-2410250                  5     14100   \n",
       "8   wb-2410252                  5     14100   \n",
       "9   wb-2410253                  5     14100   \n",
       "10  wb-2410254                  5     14100   \n",
       "11  wb-2410256                  5     14100   \n",
       "12  wb-2410257                  5     14100   \n",
       "13  wb-2410262                  5     14100   \n",
       "14  wb-2410263                  5     14100   \n",
       "15  wb-2410264                  5     14100   \n",
       "15  wb-2410264                  5     14100   \n",
       "\n",
       "                              run_name  \\\n",
       "0   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "0   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "1   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "2   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "3   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "4   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "5   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "6   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "7   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "8   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "9   1884413_wb-2410249_29-hr_14100-cfs   \n",
       "10  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "11  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "12  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "13  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "14  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "15  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "15  1884413_wb-2410249_29-hr_14100-cfs   \n",
       "\n",
       "                                             geometry  \n",
       "0   POLYGON ((2992649.306 10278157.295, 2992576.47...  \n",
       "0   POLYGON ((2989882.070 10278412.128, 2989880.57...  \n",
       "1   POLYGON ((3027376.471 10269306.529, 3027176.47...  \n",
       "2   POLYGON ((3052642.639 10239632.368, 3052470.49...  \n",
       "3   POLYGON ((3055911.199 10237312.998, 3055790.65...  \n",
       "4   POLYGON ((3065036.132 10228181.509, 3064839.22...  \n",
       "5   POLYGON ((3079876.910 10224539.263, 3079734.02...  \n",
       "6   POLYGON ((2954641.059 10296841.940, 2954644.95...  \n",
       "7   POLYGON ((2978767.625 10288850.487, 2978608.88...  \n",
       "8   POLYGON ((3001776.471 10275506.529, 3001725.46...  \n",
       "9   POLYGON ((3007176.471 10273906.529, 3006976.47...  \n",
       "10  POLYGON ((3020861.254 10269748.744, 3020776.47...  \n",
       "11  POLYGON ((3039024.147 10266386.464, 3038815.27...  \n",
       "12  POLYGON ((3050206.936 10252017.689, 3050207.53...  \n",
       "13  POLYGON ((3087213.356 10224104.042, 3087129.51...  \n",
       "14  POLYGON ((3094394.796 10220648.777, 3094312.98...  \n",
       "15  POLYGON ((3114583.903 10215935.406, 3114683.90...  \n",
       "15  POLYGON ((3113783.903 10216735.406, 3113883.90...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_buffered_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45fa5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 'time to stable' for each buffered flowpath, the count of cells in the area\n",
    "# and the count of unstable cells in the area\n",
    "\n",
    "# Create empty lists to store results\n",
    "highest_hours = []\n",
    "lowest_hours = []\n",
    "cell_count = []\n",
    "negative_one_count = []\n",
    "\n",
    "# Iterate over each row in gdf_buffered_polygon\n",
    "for index, row in gdf_buffered_polygon.iterrows():\n",
    "    # Intersect the polygon geometry with gdf_cells_wsel\n",
    "    intersected_cells = gdf_cells_wsel[gdf_cells_wsel.intersects(row['geometry'])]\n",
    "    int_cell_count = len(intersected_cells)\n",
    "    \n",
    "    # If there are intersected cells\n",
    "    if not intersected_cells.empty:\n",
    "        # Calculate highest and lowest hours_to_stable\n",
    "        highest_hour = intersected_cells['hours_to_stable'].max()\n",
    "        lowest_hour = intersected_cells['hours_to_stable'].min()\n",
    "        # Count the number of cells where the value is -1\n",
    "        negative_one_count_value = (intersected_cells['hours_to_stable'] == -1).sum()\n",
    "    else:\n",
    "        # If no intersection, set to None\n",
    "        highest_hour = None\n",
    "        lowest_hour = None\n",
    "        negative_one_count_value = None\n",
    "        \n",
    "    \n",
    "    # Append results to lists\n",
    "    highest_hours.append(highest_hour)\n",
    "    lowest_hours.append(lowest_hour)\n",
    "    cell_count.append(int_cell_count)\n",
    "    negative_one_count.append(negative_one_count_value)\n",
    "\n",
    "# Add the highest and lowest hours, cell count, and negative one count to the original GeoDataFrame\n",
    "gdf_buffered_polygon['highest_hours_to_stable'] = highest_hours\n",
    "gdf_buffered_polygon['lowest_hours_to_stable'] = lowest_hours\n",
    "gdf_buffered_polygon['cell_count'] = cell_count\n",
    "gdf_buffered_polygon['unstable_cell_count'] = negative_one_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "829bd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create layer of streams computed, including percentage of stream line that is 'wet' and 'stable' ---\n",
    "# Create a geodataframe of the streams that are in list_unique_stream_ids\n",
    "\n",
    "# Select rows where 'id' column is in list_unique_stream_ids\n",
    "gdf_streams_in_simulation = gdf_all_streams[gdf_all_streams['id'].isin(list_unique_stream_ids)]\n",
    "\n",
    "# cells with only the 'hours_to_stable' attribute\n",
    "gdf_cells_wsel_light = gdf_cells_wsel[['geometry', 'hours_to_stable']].copy()\n",
    "\n",
    "gdf_streams_in_simulation_light = gdf_streams_in_simulation[['geometry','id', 'mainstem',\n",
    "                                                             'order','tot_drainage_areasqkm']].copy()\n",
    "\n",
    "# Perform geometric overlay to compute intersection\n",
    "gdf_cell_intersection = gpd.overlay(gdf_streams_in_simulation_light, gdf_cells_wsel_light, how='intersection')\n",
    "\n",
    "# Calculate length of each line\n",
    "gdf_cell_intersection['segment_length'] = gdf_cell_intersection.geometry.length\n",
    "\n",
    "# Calculte length of the entire stream reach\n",
    "gdf_streams_in_simulation_light['length'] = gdf_streams_in_simulation_light.geometry.length\n",
    "\n",
    "# create pandas series that is sum of segment_length by unique 'id'\n",
    "ps_sum_segment_length = gdf_cell_intersection.groupby('id')['segment_length'].sum()\n",
    "\n",
    "# create pandas series that is sum of segment_length by unique 'id' where the stream is 'stable'\n",
    "filtered_df = gdf_cell_intersection[gdf_cell_intersection['hours_to_stable'] > 0]\n",
    "ps_sum_segment_length_stable = filtered_df.groupby('id')['segment_length'].sum()\n",
    "\n",
    "# Compute the percent of the stream that is 'wet' and the percentrage that the stream is 'stable'\n",
    "\n",
    "# Merge the GeoDataFrame with the pandas Series based on the 'id' column\n",
    "merged_df = gdf_streams_in_simulation_light.merge(ps_sum_segment_length_stable.rename('wet_length'), left_on='id', right_index=True)\n",
    "\n",
    "# Merge the GeoDataFrame with the pandas Series based on the 'id' column\n",
    "gdf_streams_w_stats = merged_df.merge(ps_sum_segment_length_stable.rename('stable_length'), left_on='id', right_index=True)\n",
    "\n",
    "# Compute percentage of stable length\n",
    "gdf_streams_w_stats['perct_wet'] = round((gdf_streams_w_stats['wet_length'] / gdf_streams_w_stats['length']) * 100,1)\n",
    "\n",
    "# Compute percentage of stable length\n",
    "gdf_streams_w_stats['perct_stable'] = round((gdf_streams_w_stats['stable_length'] / gdf_streams_w_stats['length']) * 100,1)\n",
    "\n",
    "# Add run name to streams \n",
    "list_unique_run = gdf_cells_wsel['run_name'].unique().tolist()\n",
    "gdf_streams_w_stats['run_name'] = list_unique_run[0] # Assumes there is only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06ac316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the HEC-RAS run info\n",
    "df_hec_info = pd.DataFrame(dict_hec_info) \n",
    "\n",
    "# Create a GeoDataFrame with a geometry column set to None\n",
    "# TODO - 2024.04.16 = for now this is a table at 0,0 as point... revise to SQLite table (no spatial data).\n",
    "gdf_hec_info = gpd.GeoDataFrame(df_hec_info, geometry=[Point(0, 0)] * len(df_hec_info))\n",
    "\n",
    "# Write GeoDataFrames to GeoPackage as separate layers\n",
    "gdf_streams_w_stats.to_file(output_path, layer='03_streams_ln', driver=\"GPKG\")\n",
    "gdf_cells_wsel.to_file(output_path, layer='02_cells_wsel_ar', driver=\"GPKG\")\n",
    "gdf_buffered_polygon.to_file(output_path, layer='01_flowpath_flooded_cells_ar', driver=\"GPKG\")\n",
    "\n",
    "gdf_hec_info.to_file(output_path, layer='00_hec_info', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b279b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
