{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650144e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440923e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Constants from config file ----\n",
    "str_boundary_to_edit = \"Emitter1\"\n",
    "\n",
    "# average time lookback to determine cells wsel 'stability' in hours\n",
    "int_time_rolling_avg = 4\n",
    "\n",
    "# additional time to extend run (in hours)\n",
    "int_buffer_time = 5\n",
    "\n",
    "# low flow in cfs for stability runs\n",
    "flt_base_flow = 500\n",
    "\n",
    "# model hydrofabric geopackage\n",
    "str_model_hydrofabric_gpkg = r'E:\\sample_2d_output\\BLE_LBSG_501_p02\\model_hydrofabric.gpkg'\n",
    "\n",
    "# directory containing the HEC-RAS files to spawn new runs/geometry\n",
    "str_ras_path = r'E:\\HECRAS_2D_12070205\\base_model_20240414_copy'\n",
    "\n",
    "int_geom_to_copy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb04ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "def fn_format_flow_as_string(flt_flow):\n",
    "    # format a flow value to no more than 5 characters\n",
    "    # if bigger than 100000 ... returns 1.0e5\n",
    "    \n",
    "    # works up to 990 million cfs\n",
    "    if flt_flow >= 100000:\n",
    "        formatted_flow = \"{:.1e}\".format(flt_flow)\n",
    "        parts = formatted_flow.split('e')\n",
    "        formatted_flow = \"{}e{}\".format(parts[0], int(parts[1]))  # Reconstructing the notation\n",
    "        if len(formatted_flow) > 8:  # Ensuring the total length is 8 characters\n",
    "            formatted_flow = \"{:.1e}\".format(flt_flow).replace(\"e\", \"e+\")\n",
    "    else:\n",
    "        formatted_flow = str(flt_flow)\n",
    "    \n",
    "    # returns a string\n",
    "    return(formatted_flow)\n",
    "# ---------------\n",
    "\n",
    "# --------------------\n",
    "def fn_list_filename_from_ras_prj(str_ras_prj_path, str_line_header):\n",
    "    # Open the file\n",
    "    with open(list_proj_title_files[0], 'r') as file:\n",
    "        # Read lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Initialize a list to store File values\n",
    "        list_names = []\n",
    "\n",
    "        # Iterate through each line\n",
    "        for line in lines:\n",
    "            # Check if the line contains \"Unsteady File\"\n",
    "            if str_line_header in line:\n",
    "                # Extract the value after \"Unsteady File=\"\n",
    "                value = line.split(str_line_header)[1].strip()\n",
    "                # Add the value to the list\n",
    "                list_names.append(value)\n",
    "        return(list_names)\n",
    "# --------------------\n",
    "\n",
    "# ----------\n",
    "def fn_extract_numbers_from_strings(lst):\n",
    "    numbers = []\n",
    "    for item in lst:\n",
    "        number = re.search(r'\\d+', item).group()\n",
    "        numbers.append(int(number))\n",
    "    return numbers\n",
    "# ----------\n",
    "\n",
    "# --------------\n",
    "def fn_list_of_file_exists(list_filepaths):\n",
    "    \n",
    "    list_b_return = []\n",
    "    for filepath in list_filepaths:\n",
    "        if os.path.exists(filepath):\n",
    "            list_b_return.append(True)\n",
    "        else:\n",
    "            list_b_return.append(False)\n",
    "    return(list_b_return)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f29efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the geopackage\n",
    "gdf_area = gpd.read_file(str_model_hydrofabric_gpkg, layer='00_area_2d')\n",
    "gdf_streams = gpd.read_file(str_model_hydrofabric_gpkg, layer='01_stream_lines')\n",
    "gdf_mainstems = gpd.read_file(str_model_hydrofabric_gpkg, layer='03_flowpaths_stabilize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f593ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "def fn_build_plan_names(flt_lower_flow, flt_upper_flow, dict_mainstem):\n",
    "    str_run_name, str_short_plan = None, None\n",
    "    \n",
    "    # systematic naming of plans (if only one flow, flt_upper_flow should be None)\n",
    "    is_single_flow = False\n",
    "    \n",
    "    try:\n",
    "        if flt_upper_flow == None:\n",
    "            is_single_flow = True\n",
    "            \n",
    "        str_mainstem = str(int(dict_mainstem['mainstem']))\n",
    "        str_start_node = dict_mainstem['id_start_node']\n",
    "        int_firehose_time = int(dict_mainstem['travel_time_hr']) + 1\n",
    "        int_firehose_time += int_time_rolling_avg + int_buffer_time\n",
    "        str_flow =  str(int(flt_lower_flow))\n",
    "\n",
    "        str_run_name = str_mainstem + \"_\" + str_start_node + \"_\" + str(int_firehose_time) + \"-\" + \"hr\"\n",
    "        str_run_name += \"_\" + str(int(flt_lower_flow)) + \"-cfs\"\n",
    "\n",
    "        if not is_single_flow:  \n",
    "            # add the upper range flow to the description\n",
    "            str_run_name += \"_to_\" + str(int(flt_upper_flow)) + \"-cfs\"\n",
    "\n",
    "        str_short_plan = str_start_node + '-' + fn_format_flow_as_string(flt_lower_flow)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return(str_run_name, str_short_plan)\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bccf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "-----\n",
      "1884794_wb-2410509_11-hr_500-cfs\n",
      "wb-2410509-500\n",
      "-----\n",
      "1884821_wb-2410523_10-hr_500-cfs\n",
      "wb-2410523-500\n",
      "-----\n",
      "1884825_wb-2410524_17-hr_500-cfs\n",
      "wb-2410524-500\n",
      "-----\n",
      "1884838_wb-2410528_11-hr_500-cfs\n",
      "wb-2410528-500\n",
      "-----\n",
      "1884841_wb-2410529_11-hr_500-cfs\n",
      "wb-2410529-500\n",
      "-----\n",
      "1884847_wb-2410530_11-hr_500-cfs\n",
      "wb-2410530-500\n",
      "-----\n",
      "1884849_wb-2410531_10-hr_500-cfs\n",
      "wb-2410531-500\n",
      "-----\n",
      "1884851_wb-2410532_11-hr_500-cfs\n",
      "wb-2410532-500\n",
      "-----\n",
      "1884853_wb-2410533_10-hr_500-cfs\n",
      "wb-2410533-500\n",
      "-----\n",
      "1884858_wb-2410534_10-hr_500-cfs\n",
      "wb-2410534-500\n",
      "-----\n",
      "1884860_wb-2410535_11-hr_500-cfs\n",
      "wb-2410535-500\n",
      "-----\n",
      "1884862_wb-2410536_11-hr_500-cfs\n",
      "wb-2410536-500\n",
      "-----\n",
      "1884864_wb-2410537_14-hr_500-cfs\n",
      "wb-2410537-500\n",
      "-----\n",
      "1884865_wb-2410541_10-hr_500-cfs\n",
      "wb-2410541-500\n",
      "-----\n",
      "1884868_wb-2410542_10-hr_500-cfs\n",
      "wb-2410542-500\n",
      "-----\n",
      "1884870_wb-2410543_10-hr_500-cfs\n",
      "wb-2410543-500\n",
      "-----\n",
      "1884873_wb-2410544_12-hr_500-cfs\n",
      "wb-2410544-500\n",
      "-----\n",
      "1884874_wb-2410546_10-hr_500-cfs\n",
      "wb-2410546-500\n",
      "-----\n",
      "1884878_wb-2410547_10-hr_500-cfs\n",
      "wb-2410547-500\n",
      "-----\n",
      "1884880_wb-2410548_10-hr_500-cfs\n",
      "wb-2410548-500\n",
      "-----\n",
      "1884884_wb-2410549_11-hr_500-cfs\n",
      "wb-2410549-500\n",
      "-----\n",
      "1884885_wb-2410550_10-hr_500-cfs\n",
      "wb-2410550-500\n",
      "-----\n",
      "1884889_wb-2410551_10-hr_500-cfs\n",
      "wb-2410551-500\n",
      "-----\n",
      "1884892_wb-2410552_10-hr_500-cfs\n",
      "wb-2410552-500\n",
      "-----\n",
      "1884894_wb-2410553_18-hr_500-cfs\n",
      "wb-2410553-500\n",
      "-----\n",
      "1884895_wb-2410559_11-hr_500-cfs\n",
      "wb-2410559-500\n",
      "-----\n",
      "1884897_wb-2410560_10-hr_500-cfs\n",
      "wb-2410560-500\n",
      "-----\n",
      "1884899_wb-2410561_11-hr_500-cfs\n",
      "wb-2410561-500\n",
      "-----\n",
      "1884901_wb-2410562_10-hr_500-cfs\n",
      "wb-2410562-500\n",
      "-----\n",
      "1884903_wb-2410563_10-hr_500-cfs\n",
      "wb-2410563-500\n",
      "-----\n",
      "1884905_wb-2410564_11-hr_500-cfs\n",
      "wb-2410564-500\n",
      "-----\n",
      "1884907_wb-2410565_10-hr_500-cfs\n",
      "wb-2410565-500\n",
      "-----\n",
      "1884910_wb-2410566_10-hr_500-cfs\n",
      "wb-2410566-500\n",
      "-----\n",
      "1884912_wb-2410567_10-hr_500-cfs\n",
      "wb-2410567-500\n",
      "-----\n",
      "1884914_wb-2410568_10-hr_500-cfs\n",
      "wb-2410568-500\n",
      "-----\n",
      "1884916_wb-2410569_10-hr_500-cfs\n",
      "wb-2410569-500\n",
      "-----\n",
      "1884918_wb-2410570_10-hr_500-cfs\n",
      "wb-2410570-500\n",
      "-----\n",
      "1884920_wb-2410571_12-hr_500-cfs\n",
      "wb-2410571-500\n",
      "-----\n",
      "1884923_wb-2410574_10-hr_500-cfs\n",
      "wb-2410574-500\n",
      "-----\n",
      "1884927_wb-2410575_11-hr_500-cfs\n",
      "wb-2410575-500\n",
      "-----\n",
      "1884413_wb-2410249_30-hr_500-cfs\n",
      "wb-2410249-500\n",
      "-----\n",
      "1884413_wb-2410264_11-hr_500-cfs\n",
      "wb-2410264-500\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for index, row in gdf_mainstems.iterrows():\n",
    "    a,b = fn_build_plan_names(flt_base_flow, None, row.to_dict())\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72007238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "def fn_list_of_ras_projects(str_ras_path):\n",
    "\n",
    "    list_proj_title_files = []\n",
    "\n",
    "    # locate the valid HEC-RAS project\n",
    "    try:\n",
    "        list_prj_files = [os.path.join(str_ras_path, f) for f in os.listdir(str_ras_path) if f.endswith('.prj')]\n",
    "\n",
    "        if len(list_prj_files) > 0:\n",
    "            list_proj_title_files = []\n",
    "\n",
    "            for file_path in list_prj_files:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    contents = file.read()\n",
    "                    if 'Proj Title' in contents:\n",
    "                        list_proj_title_files.append(file_path)\n",
    "\n",
    "            for file_path in list_proj_title_files:\n",
    "                print(f\"Valid HEC-RAS Project: {file_path}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"No HEC-RAS PRJ found in {str_ras_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    return(list_proj_title_files)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc226b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ....................\n",
    "def fn_copy_geom_file(list_proj_title_files, int_geom_to_copy):\n",
    "    \n",
    "    str_copy_to_geom_full_path = None\n",
    "    str_copy_to_geom_hdf_full_path = None\n",
    "\n",
    "    # Splitting the path into folder and filename\n",
    "    str_prj_folder, str_filename = os.path.split(list_proj_title_files[0])\n",
    "\n",
    "    # Splitting the filename and its extension\n",
    "    str_file_only, str_extension = os.path.splitext(str_filename)\n",
    "\n",
    "    # determine the geometry files that are in the project\n",
    "    list_geom_names = fn_list_filename_from_ras_prj(list_proj_title_files[0], \"Geom File=\")\n",
    "    list_geom_int = fn_extract_numbers_from_strings(list_geom_names)\n",
    "\n",
    "    list_geom_hdf_fullpath = []\n",
    "    list_geom_fullpath = []\n",
    "\n",
    "    for geom_item in list_geom_names:\n",
    "        str_hdf_geom_file = str_file_only + \".\" + geom_item + \".hdf\"\n",
    "        str_geom_file = str_file_only + \".\" + geom_item\n",
    "\n",
    "        # Combine the folder path and filename\n",
    "        str_hdf_full_path = os.path.join(str_prj_folder, str_hdf_geom_file)\n",
    "        str_geom_full_path = os.path.join(str_prj_folder, str_geom_file)\n",
    "\n",
    "        list_geom_hdf_fullpath.append(str_hdf_full_path)\n",
    "        list_geom_fullpath.append(str_geom_full_path)\n",
    "\n",
    "    list_b_hdf_exists = []\n",
    "\n",
    "    list_b_hdf_exists = fn_list_of_file_exists(list_geom_hdf_fullpath)\n",
    "    list_b_geom_exists = fn_list_of_file_exists(list_geom_fullpath)\n",
    "\n",
    "    # Assuming all lists have the same length\n",
    "    data = {\n",
    "        'geom_int': list_geom_int,\n",
    "        'geom_name': list_geom_names,\n",
    "        'hdf_path': list_geom_hdf_fullpath,\n",
    "        'hdf_exists': list_b_hdf_exists,\n",
    "        'geom_path': list_geom_fullpath,\n",
    "        'geom_exists': list_b_geom_exists\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df[(df['geom_int'] == int_geom_to_copy) & (df['hdf_exists']) & (df['geom_exists'])]\n",
    "\n",
    "    # Check if any rows match the condition\n",
    "    if not df_filtered.empty:\n",
    "        # If there's at least one row matching the condition\n",
    "        print('Valid Geometry Match Found')\n",
    "\n",
    "        # Determine the highest number in geom_int\n",
    "        highest_geom_int = df['geom_int'].max()\n",
    "\n",
    "        # Add one to the highest number\n",
    "        next_geom_int = highest_geom_int + 1\n",
    "\n",
    "        # Convert next_geom_int to string with leading zero padding if necessary\n",
    "        next_geom_int_str = '{:02d}'.format(next_geom_int)\n",
    "\n",
    "        # copy geom file\n",
    "        str_copy_from = df_filtered.iloc[0]['geom_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str\n",
    "        str_copy_to_geom_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from, str_copy_to_geom_full_path)\n",
    "        print(f\"Copied {str_copy_from} to {str_copy_to_geom_full_path}\")\n",
    "\n",
    "        # copy the hdf geom file\n",
    "        str_copy_from_hdf = df_filtered.iloc[0]['hdf_path']\n",
    "        str_copy_to_geom = str_file_only + \".g\" + next_geom_int_str + \".hdf\"\n",
    "        str_copy_to_geom_hdf_full_path = os.path.join(str_prj_folder, str_copy_to_geom)\n",
    "\n",
    "        shutil.copy(str_copy_from_hdf, str_copy_to_geom_hdf_full_path)\n",
    "        print(f\"Copied {str_copy_from_hdf} to {str_copy_to_geom_hdf_full_path}\")\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~\n",
    "        # add the geom to the project file\n",
    "\n",
    "        # Read the contents of the file\n",
    "        with open(list_proj_title_files[0], 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the last occurrence of a line starting with \"Geom File=\"\n",
    "        last_geom_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].strip().startswith(\"Geom File=\"):\n",
    "                last_geom_index = i\n",
    "\n",
    "        # Insert a new line after the last occurrence of \"Geom File=\"\n",
    "        if last_geom_index != -1:\n",
    "            lines.insert(last_geom_index + 1, \"Geom File=g\" + next_geom_int_str + \"\\n\")\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(list_proj_title_files[0], 'w') as file:\n",
    "            file.writelines(lines)\n",
    "\n",
    "    else:\n",
    "        # Otherwise, print an error statement\n",
    "        print(\"Error: Geometry HDF and gXX not available.\")\n",
    "        \n",
    "    return(str_copy_to_geom_full_path, str_copy_to_geom_hdf_full_path)\n",
    "# ...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_proj_title_files = fn_list_of_ras_projects(str_ras_path)\n",
    "str_copy_to_geom, str_copy_to_geom_hdf = fn_copy_geom_file(list_proj_title_files, int_geom_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f152829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
